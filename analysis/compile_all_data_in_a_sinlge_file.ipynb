{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "from questions_construction.main import QUESTION_CATEGORIES\n",
    "from questions_construction.domains import DOMAIN_NAMES\n",
    "from common import *\n",
    "from model_performances import *\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T01:58:27.763098Z",
     "start_time": "2024-10-01T01:58:23.020308Z"
    }
   },
   "id": "f00c8b899d1bb41",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "substitution=WITHOUT_RANDOM_SUB\n",
    "ramification=WITHOUT_RAMIFICATIONS\n",
    "prompt_type=ZERO_SHOT_PROMPT_KEY\n",
    "questions_by_id = {d[OUT_OBJ_ID]: d for d in open_jsonl(f'{DATA_PATH}/test_data.paraphrased.cleaned.jsonl')}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T02:01:51.517160Z",
     "start_time": "2024-10-01T02:01:51.322766Z"
    }
   },
   "id": "8d6af460ab228cff",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_keys(d):\n",
    "    for rm_key in ['label', 'checkpoint_130_generated_responses', 'input_prompt_tokenized', 'answer_tokenized', 'input_prompt_tokenized']:\n",
    "        if rm_key in d:\n",
    "            del d[rm_key]\n",
    "    return d\n",
    "\n",
    "def load_all_data(model_name, substitution=WITHOUT_RANDOM_SUB, ramification=WITHOUT_RAMIFICATIONS, prompt_type=ZERO_SHOT_PROMPT_KEY):\n",
    "    questions_by_id = {d[OUT_OBJ_ID]: d for d in open_jsonl(f'{DATA_PATH}/test_data.paraphrased.cleaned.jsonl')}\n",
    "    \n",
    "    # True/False\n",
    "    model_tf_results = open_jsonl(f'{PROJECT_PATH}/data/prompting_results/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "    data_tf = data_all_single_run(questions_by_id, model_tf_results, substitution, ramification, model_name,prompt_type)\n",
    "    data_tf_by_id = {d[OUT_OBJ_ID]: d for d in data_tf}\n",
    "    \n",
    "    model_free_results = open_jsonl(f'{PROJECT_PATH}/data/free_answers/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "    data_free = data_all_single_run(questions_by_id, model_free_results, substitution, ramification, model_name, prompt_type)\n",
    "    data_free_by_id = {d[OUT_OBJ_ID]: d for d in data_free}\n",
    "    \n",
    "    zipped_data = []\n",
    "    for q_id in questions_by_id:\n",
    "        d = {}\n",
    "        if q_id in data_tf_by_id:\n",
    "            d.update(data_tf_by_id[q_id])\n",
    "        if q_id in data_free_by_id:\n",
    "            d.update(data_free_by_id[q_id])\n",
    "        if d:\n",
    "            d = remove_keys(d)\n",
    "            zipped_data.append(d)\n",
    "    return zipped_data\n",
    "\n",
    "def prediction_criteria(d, prediction, ground_truth):\n",
    "    if prediction in (TRUE_ANSWER, FALSE_ANSWER):\n",
    "        if prediction == ground_truth:\n",
    "            d[IS_RESPONSE_CORRECT_KEY] = TRUE_ANSWER\n",
    "        else:\n",
    "            d[IS_RESPONSE_CORRECT_KEY] = FALSE_ANSWER\n",
    "    else:\n",
    "        # print(prediction, ground_truth)\n",
    "        d[IS_RESPONSE_CORRECT_KEY] = 'N/A'\n",
    "        \n",
    "    return d\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T02:05:44.339030Z",
     "start_time": "2024-10-01T02:05:44.330066Z"
    }
   },
   "id": "ac50b738361b873f",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'evaluated_free_answer_response'\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['llama_8b', 'llama_70b', 'gpt-4o']:\n",
    "    data_all = load_all_data(model_name)\n",
    "    \n",
    "    for d in data_all:\n",
    "        try:\n",
    "            if d[OUT_OBJ_ANSWER_TYPE] == TRUE_FALSE_ANSWER_TYPE:\n",
    "                prediction = TrueFalseStats.prediction_selection_criteria(d)\n",
    "                ground_truth = d[OUT_OBJ_ANSWER]\n",
    "            else:\n",
    "                prediction = FreeAnswerStats.prediction_selection_criteria(d)\n",
    "                ground_truth = TRUE_ANSWER\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            ground_truth = 'xdskjnf'\n",
    "            prediction = 'sjsnf'\n",
    "        \n",
    "        d = prediction_criteria(d, prediction, ground_truth)   \n",
    "    save_jsonl(data_all, f'{model_name}.all.jsonl')"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T02:05:48.118441Z",
     "start_time": "2024-10-01T02:05:44.862075Z"
    }
   },
   "id": "initial_id",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_name = 'llama_8b.finetuned_free'\n",
    "model_free_results = open_jsonl(f'{PROJECT_PATH}/data/free_answers/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "data_all = data_all_single_run(questions_by_id, model_free_results, substitution, ramification, model_name, prompt_type)\n",
    "\n",
    "data_pruned = []\n",
    "for d in data_all:\n",
    "    if d[OUT_OBJ_ANSWER_TYPE] != FREE_ANSWER_TYPE:\n",
    "        continue\n",
    "    prediction = FreeAnswerStats.prediction_selection_criteria(d)\n",
    "    ground_truth = TRUE_ANSWER   \n",
    "    d = prediction_criteria(d, prediction, ground_truth) \n",
    "    d = remove_keys(d)\n",
    "    data_pruned.append(d)\n",
    "    \n",
    "save_jsonl(data_pruned, f'{model_name}.all.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T02:05:49.522941Z",
     "start_time": "2024-10-01T02:05:48.120010Z"
    }
   },
   "id": "e2c10a85035e2c47",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_name = 'llama_8b.finetuned_tf'\n",
    "model_tf_results = open_jsonl(f'{PROJECT_PATH}/data/prompting_results/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "data_all = data_all_single_run(questions_by_id, model_tf_results, substitution, ramification, model_name,prompt_type)\n",
    "\n",
    "\n",
    "data_pruned = []\n",
    "for d in data_all:\n",
    "    if d[OUT_OBJ_ANSWER_TYPE] != TRUE_FALSE_ANSWER_TYPE:\n",
    "        continue \n",
    "    prediction = TrueFalseStats.prediction_selection_criteria(d)\n",
    "    ground_truth = d[OUT_OBJ_ANSWER]\n",
    "    d = prediction_criteria(d, prediction, ground_truth)  \n",
    "    d = remove_keys(d)\n",
    "    data_pruned.append(d)\n",
    "        \n",
    "save_jsonl(data_pruned, f'{model_name}.all.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T02:05:50.385799Z",
     "start_time": "2024-10-01T02:05:49.524377Z"
    }
   },
   "id": "6323c8cf4bee4259",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = open_jsonl('gpt-4o.all.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:50:27.638984Z",
     "start_time": "2024-10-01T07:50:26.552549Z"
    }
   },
   "id": "efc5d2397e4f85d8",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scores = []\n",
    "for d in data:\n",
    "    if d['plan_length'] == 1 and d['answer_type'] == TRUE_FALSE_ANSWER_TYPE and d['is_response_correct'] in (TRUE_ANSWER, FALSE_ANSWER):\n",
    "        scores.append(d['is_response_correct']=='True')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:56:24.724712Z",
     "start_time": "2024-10-01T07:56:24.668173Z"
    }
   },
   "id": "d104e30f258a207b",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.8126195028680688"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:56:25.348970Z",
     "start_time": "2024-10-01T07:56:25.343487Z"
    }
   },
   "id": "cf7af6a2f7701032",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "713"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T07:54:31.956854Z",
     "start_time": "2024-10-01T07:54:31.938842Z"
    }
   },
   "id": "ec2eaf8b2e3ef15e",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3ca937c316d8a857"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

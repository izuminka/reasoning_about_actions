{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "from questions_construction.main import QUESTION_CATEGORIES\n",
    "from questions_construction.domains import DOMAIN_NAMES\n",
    "from common import *\n",
    "from model_performances import *\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T00:54:37.280834Z",
     "start_time": "2024-10-01T00:54:37.265530Z"
    }
   },
   "id": "f00c8b899d1bb41",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_all_data(model_name, substitution=WITHOUT_RANDOM_SUB, ramification=WITHOUT_RAMIFICATIONS, prompt_type=ZERO_SHOT_PROMPT_KEY):\n",
    "    questions_by_id = {d[OUT_OBJ_ID]: d for d in open_jsonl(f'{DATA_PATH}/test_data.paraphrased.cleaned.jsonl')}\n",
    "    \n",
    "    # True/False\n",
    "    model_tf_results = open_jsonl(f'{PROJECT_PATH}/data/prompting_results/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "    data_tf = data_all_single_run(questions_by_id, model_tf_results, substitution, ramification, model_name,prompt_type)\n",
    "    data_tf_by_id = {d[OUT_OBJ_ID]: d for d in data_tf}\n",
    "    \n",
    "    model_free_results = open_jsonl(f'{PROJECT_PATH}/data/free_answers/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "    data_free = data_all_single_run(questions_by_id, model_free_results, substitution, ramification, model_name, prompt_type)\n",
    "    data_free_by_id = {d[OUT_OBJ_ID]: d for d in data_free}\n",
    "    \n",
    "    zipped_data = []\n",
    "    for q_id in questions_by_id:\n",
    "        d = {}\n",
    "        if q_id in data_tf_by_id:\n",
    "            d.update(data_tf_by_id[q_id])\n",
    "        if q_id in data_free_by_id:\n",
    "            d.update(data_free_by_id[q_id])\n",
    "        if d:\n",
    "            zipped_data.append(d)\n",
    "    return zipped_data\n",
    "\n",
    "def prediction_criteria(d, prediction, ground_truth):\n",
    "    if prediction in (TRUE_ANSWER, FALSE_ANSWER):\n",
    "        if prediction == ground_truth:\n",
    "            d[IS_RESPONSE_CORRECT_KEY] = TRUE_ANSWER\n",
    "        else:\n",
    "            d[IS_RESPONSE_CORRECT_KEY] = FALSE_ANSWER\n",
    "    else:\n",
    "        # print(prediction, ground_truth)\n",
    "        d[IS_RESPONSE_CORRECT_KEY] = 'N/A'\n",
    "        \n",
    "    return d\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T01:44:22.639543Z",
     "start_time": "2024-10-01T01:44:22.631118Z"
    }
   },
   "id": "ac50b738361b873f",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'evaluated_free_answer_response'\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['llama_8b', 'llama_70b', 'gpt-4o']:\n",
    "    data_all = load_all_data(model_name)\n",
    "    \n",
    "    for d in data_all:\n",
    "        try:\n",
    "            if d[OUT_OBJ_ANSWER_TYPE] == TRUE_FALSE_ANSWER_TYPE:\n",
    "                prediction = TrueFalseStats.prediction_selection_criteria(d)\n",
    "                ground_truth = d[OUT_OBJ_ANSWER]\n",
    "            else:\n",
    "                prediction = FreeAnswerStats.prediction_selection_criteria(d)\n",
    "                ground_truth = TRUE_ANSWER\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            ground_truth = 'xdskjnf'\n",
    "            prediction = 'sjsnf'\n",
    "        \n",
    "        d = prediction_criteria(d, prediction, ground_truth)   \n",
    "    save_jsonl(data_all, f'{model_name}.all.jsonl')"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T01:44:26.810416Z",
     "start_time": "2024-10-01T01:44:23.320129Z"
    }
   },
   "id": "initial_id",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_name = 'llama_8b.finetuned_free'\n",
    "model_free_results = open_jsonl(f'{PROJECT_PATH}/data/free_answers/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "data_all = data_all_single_run(questions_by_id, model_free_results, substitution, ramification, model_name, prompt_type)\n",
    "\n",
    "data_pruned = []\n",
    "for d in data_all:\n",
    "    if d[OUT_OBJ_ANSWER_TYPE] != FREE_ANSWER_TYPE:\n",
    "        continue\n",
    "    prediction = FreeAnswerStats.prediction_selection_criteria(d)\n",
    "    ground_truth = TRUE_ANSWER   \n",
    "    d = prediction_criteria(d, prediction, ground_truth)   \n",
    "    data_pruned.append(d)\n",
    "        \n",
    "save_jsonl(data_pruned, f'{model_name}.all.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T01:44:31.797546Z",
     "start_time": "2024-10-01T01:44:30.163122Z"
    }
   },
   "id": "e2c10a85035e2c47",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_name = 'llama_8b.finetuned_tf'\n",
    "model_tf_results = open_jsonl(f'{PROJECT_PATH}/data/prompting_results/{ramification}/{prompt_type}/{model_name}.jsonl')\n",
    "data_all = data_all_single_run(questions_by_id, model_tf_results, substitution, ramification, model_name,prompt_type)\n",
    "\n",
    "\n",
    "data_pruned = []\n",
    "for d in data_all:\n",
    "    if d[OUT_OBJ_ANSWER_TYPE] != TRUE_FALSE_ANSWER_TYPE:\n",
    "        continue\n",
    "        \n",
    "    prediction = TrueFalseStats.prediction_selection_criteria(d)\n",
    "    ground_truth = d[OUT_OBJ_ANSWER]\n",
    "    d = prediction_criteria(d, prediction, ground_truth)   \n",
    "    data_pruned.append(d)\n",
    "        \n",
    "save_jsonl(data_pruned, f'{model_name}.all.jsonl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-01T01:44:38.508457Z",
     "start_time": "2024-10-01T01:44:37.251500Z"
    }
   },
   "id": "6323c8cf4bee4259",
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

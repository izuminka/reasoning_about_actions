{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('..')\n",
    "from common import *\n",
    "from analysis.model_performances import *\n",
    "from copy import deepcopy\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "\n",
    "CONF_KEY = 'sem'\n",
    "\n",
    "def latex_table_mods(latex_table):\n",
    "    return latex_table.replace('{lllllllllllll}','{l|ll|ll|ll|ll||ll|ll}').replace('${None}_{None}$', '---')\n",
    "\n",
    "model_names =  ['gpt-4o', 'llama_8b','llama_70b', ]#'llama_8b.finetuned_free'#'llama_8b.finetuned_tf']#, 'gemini', 'llama2-13b-chat', 'llama-3-8b-instruct', 'llama2-7b-chat', 'gemma-7b'] + ['llama-3-8b-instruct-finetuned','gemma-7b-finetuned']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T03:19:13.312195Z",
     "start_time": "2024-10-02T03:19:13.307223Z"
    }
   },
   "id": "1581e9208ff09f8e",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40320/40320 [00:00<00:00, 56722.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer_type = TRUE_FALSE_ANSWER_TYPE# FREE_ANSWER_TYPE #\n",
    "answer_type_ext = f'{answer_type}.{ACCURACY_SCORE_KEY}'\n",
    "\n",
    "# ids_file_name = 'dataset_ids.test.pruned'  # None\n",
    "# save_main_dir = f'{STATISTICS_PATH}.{ids_file_name}'\n",
    "save_main_dir = f'{STATISTICS_PATH}.trial_run.ED'\n",
    "stats_all = collect_stats_all(answer_type_ext, save_main_dir=save_main_dir)\n",
    "print(len(stats_all))\n",
    "plan_lengths = [1,10,19]\n",
    "\n",
    "save_dir = os.path.join(save_main_dir, 'tables', 'by_models')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T03:20:39.905882Z",
     "start_time": "2024-10-02T03:20:39.185515Z"
    }
   },
   "id": "8fb4feeb322b4ab0",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for d in stats_all:\n",
    "#     if d['model'] == 'llama_8b.finetuned_free':\n",
    "#         print('sdfs')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T03:20:40.465368Z",
     "start_time": "2024-10-02T03:20:40.462847Z"
    }
   },
   "id": "c3a3729a880506b5",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def to_df_by_len_by_category(results_all, answer_type, prompt_type,\n",
    "                      model_names = PROMPT_MODEL_NAMES,\n",
    "                      ramifications = WITHOUT_RAMIFICATIONS,\n",
    "                      domain = ALL_DOMAINS_KEY, \n",
    "                      subs = WITHOUT_RANDOM_SUB):\n",
    "\n",
    "    index = []\n",
    "    data = []    \n",
    "    for plan_length in PLAN_LENGTHS:\n",
    "        for question_category in QUESTION_CATEGORIES+[ALL_QUESTION_CATEGORIES_KEY]:\n",
    "            index.append((plan_length, TO_PRETTY.get(question_category,question_category)))\n",
    "            # index.append('{}')\n",
    "            data_columns = {}\n",
    "            data_columns['plan pength'] = plan_length\n",
    "            data_columns['question category'] = TO_PRETTY.get(question_category,question_category)\n",
    "            for model_name in model_names:\n",
    "                res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "                if res_obj:\n",
    "                    mean = res_obj['result']\n",
    "                    sem = None\n",
    "                    if res_obj['result_other']:\n",
    "                        sem = res_obj['result_other'][CONF_KEY]\n",
    "                    not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                    final_res = (mean, sem, not_corrupted)\n",
    "                else:\n",
    "                    final_res = (None, None, None)\n",
    "                final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "                final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "                data_columns[(TO_PRETTY.get(model_name,model_name), TO_PRETTY.get(prompt_type,prompt_type))] = final_res\n",
    "            data.append(data_columns)\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def to_df_few_shot(results_all, answer_type, \n",
    "                   plan_length=19,\n",
    "                      model_names = PROMPT_MODEL_NAMES,\n",
    "                      ramifications = WITHOUT_RAMIFICATIONS,\n",
    "                   question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "                      domain = ALL_DOMAINS_KEY, \n",
    "                      subs = WITHOUT_RANDOM_SUB):\n",
    "\n",
    "    index = []\n",
    "    data = []    \n",
    "    for prompt_type in PROMPT_TYPES:\n",
    "        index.append(prompt_type)\n",
    "        data_columns = {}\n",
    "        data_columns['prompt'] = prompt_type\n",
    "        for model_name in model_names:\n",
    "            res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "            if res_obj:\n",
    "                mean = res_obj['result']\n",
    "                sem = None\n",
    "                if res_obj['result_other']:\n",
    "                    sem = res_obj['result_other'][CONF_KEY]\n",
    "                not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                final_res = (mean, sem, not_corrupted)\n",
    "            else:\n",
    "                final_res = (None, None, None)\n",
    "            final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "            final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "            data_columns[TO_PRETTY.get(model_name,model_name)] = final_res\n",
    "        data.append(data_columns)\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def to_df_few_shot_by_category(results_all, answer_type, \n",
    "                               plan_length=19, model_names = PROMPT_MODEL_NAMES,\n",
    "                      ramifications = WITHOUT_RAMIFICATIONS,\n",
    "                   question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "                      domain = ALL_DOMAINS_KEY, \n",
    "                      subs = WITHOUT_RANDOM_SUB):\n",
    "\n",
    "    data = []    \n",
    "    for question_category in QUESTION_CATEGORIES+[ALL_QUESTION_CATEGORIES_KEY]:\n",
    "        if question_category == 'composite':\n",
    "            continue\n",
    "        data_columns = {}\n",
    "        data_columns['question category'] = TO_PRETTY.get(question_category,question_category)\n",
    "        for model_name in model_names:\n",
    "            for prompt_type in  ['few_shot_0', 'few_shot_1', 'few_shot_5']:\n",
    "                res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "                if res_obj:\n",
    "                    mean = res_obj['result']\n",
    "                    sem = None\n",
    "                    if res_obj['result_other']:\n",
    "                        sem = res_obj['result_other'][CONF_KEY]\n",
    "                    not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                    final_res = (mean, sem, not_corrupted)\n",
    "                else:\n",
    "                    final_res = (None, None, None)\n",
    "                final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "                final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "                data_columns[(TO_PRETTY.get(model_name,model_name),prompt_type)] = final_res\n",
    "        data.append(data_columns)\n",
    "    return pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T03:20:40.815355Z",
     "start_time": "2024-10-02T03:20:40.793776Z"
    }
   },
   "id": "dd77fda858739d0e",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def to_df(results_all, plan_lengths, answer_type, models=PROMPT_MODEL_NAMES,\n",
    "#           prompt_types = PROMPT_TYPES,\n",
    "#           domain = ALL_DOMAINS_KEY, subs = WITHOUT_RANDOM_SUB):\n",
    "#     \n",
    "#     index = []\n",
    "#     data = []    \n",
    "#     for plan_length in plan_lengths:\n",
    "#         for ramifications in RAMIFICATION_TYPES:\n",
    "#             index.append((plan_length, TO_PRETTY.get(ramifications, ramifications)))\n",
    "#             # data_columns = {}\n",
    "#             for model_name in models:\n",
    "#                 for prompt_type in prompt_types:\n",
    "#                     res_obj = filter_single_selector(results_all, plan_length, ALL_QUESTION_CATEGORIES_KEY, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "#                     # print(res_obj)\n",
    "#                     if res_obj:\n",
    "#                         mean = res_obj['result']\n",
    "#                         sem = None\n",
    "#                         if res_obj['result_other']:\n",
    "#                             sem = res_obj['result_other'][CONF_KEY]\n",
    "#                         not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "#                         final_res = (mean, sem, not_corrupted)\n",
    "#                     else:\n",
    "#                         final_res = (None, None, None)\n",
    "#                     final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "#                     final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "#                     data_columns[(TO_PRETTY.get(model_name, model_name), TO_PRETTY.get(prompt_type, prompt_type))] = final_res\n",
    "#             data.append(data_columns)\n",
    "#     return pd.DataFrame(data, index = index)\n",
    "# \n",
    "# def to_df_by_category(results_all, answer_type,  \n",
    "#                       model_names = PROMPT_MODEL_NAMES,\n",
    "#                       prompt_types= PROMPT_TYPES,\n",
    "#                       ramifications = WITHOUT_RAMIFICATIONS,\n",
    "#                       domain = ALL_DOMAINS_KEY, \n",
    "#                       subs = WITHOUT_RANDOM_SUB,\n",
    "#                       plan_length=19):\n",
    "# \n",
    "#     index = []\n",
    "#     data = []    \n",
    "#     for question_category in QUESTION_CATEGORIES:\n",
    "#         index.append(question_category)\n",
    "#         data_columns = {}\n",
    "#         for model_name in model_names:\n",
    "#             for prompt_type in prompt_types:\n",
    "#                 res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "#                 if res_obj:\n",
    "#                     mean = res_obj['result']\n",
    "#                     sem = None\n",
    "#                     if res_obj['result_other']:\n",
    "#                         sem = res_obj['result_other'][CONF_KEY]\n",
    "#                     not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "#                     final_res = (mean, sem, not_corrupted)\n",
    "#                 else:\n",
    "#                     final_res = (None, None, None)\n",
    "#                 final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "#                 final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "#                 data_columns[(TO_PRETTY.get(model_name,model_name), TO_PRETTY.get(prompt_type,prompt_type))] = final_res\n",
    "#         data.append(data_columns)\n",
    "#     return pd.DataFrame(data, index = index)\n",
    "\n",
    "# models_for_plot =  ['gemini', 'gpt-4o'] + ['llama2-13b-chat', 'llama-3-8b-instruct','gemma-7b'] + ['llama-3-8b-tuned','gemma-7b-tuned']\n",
    "# # model_prompts_combos = [('small-models', SMALL_MODELS, PROMPT_TYPES), ('big-models', BIG_MODELS, ['few_shot_1', 'few_shot_5'])]\n",
    "# model_prompts_combos = [('all-models', PROMPT_MODEL_NAMES, ['few_shot_1', 'few_shot_5'])]\n",
    "# \n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for model_save_name, model_names, prompt_types in model_prompts_combos:\n",
    "#         df = to_df(stats_all, plan_lengths, answer_type, prompt_types=prompt_types, models=model_names, subs=subs)\n",
    "#         print(df)\n",
    "#         \n",
    "#         caption_nl = f'performance of {model_save_name} on the test set, {subs}'.replace('_', ' ')\n",
    "#         latex_table = latex_table_mods(to_latex_table(df, caption_nl, label=model_save_name))\n",
    "#         save_key = f'all.{model_save_name}.{subs}'\n",
    "#         with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#             f.write(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T03:20:41.197146Z",
     "start_time": "2024-10-02T03:20:41.191274Z"
    }
   },
   "id": "5b5a15905194ac6a",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot By Category"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aad3ef5e3825084"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plan_length = 19\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for model_save_name, model_names, prompt_types in model_prompts_combos:\n",
    "#         df2 = to_df_by_category(stats_all, answer_type, model_names=model_names, prompt_types=prompt_types, subs=subs)\n",
    "#         print(df2)\n",
    "#         \n",
    "#         caption_nl = f'performance of {model_save_name} on the test set by categories, {subs}, pl-{plan_length}'\n",
    "#         save_key = f'by_categories.{model_save_name}.{subs}'\n",
    "#         \n",
    "#         latex_table_all = latex_table_mods(to_latex_table(df2, caption_nl, label=save_key))\n",
    "#         with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#             f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T03:20:41.918002Z",
     "start_time": "2024-10-02T03:20:41.914832Z"
    }
   },
   "id": "da82c99c16ce0495",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "# By Category By Length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9267d96722ee7613"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                    plan pength question category    (gpt-4o, FS-3)  \\\n(1, State Trk.)               1        State Trk.  ${91.57}_{3.05}$   \n(1, Fluent Trk.)              1       Fluent Trk.   ${85.0}_{3.57}$   \n(1, Action Exec.)             1      Action Exec.   ${95.1}_{2.14}$   \n(1, Effects)                  1           Effects  ${74.19}_{4.54}$   \n(1, Num. Reas.)               1        Num. Reas.  ${58.54}_{5.44}$   \n(1, Composite)                1         Composite   ${82.66}_{2.4}$   \n(1, AVG)                      1               AVG  ${81.92}_{1.45}$   \n(10, State Trk.)             10        State Trk.   ${91.55}_{3.3}$   \n(10, Fluent Trk.)            10       Fluent Trk.  ${84.54}_{3.67}$   \n(10, Action Exec.)           10      Action Exec.  ${73.79}_{4.33}$   \n(10, Effects)                10           Effects  ${59.18}_{4.96}$   \n(10, Num. Reas.)             10        Num. Reas.  ${41.67}_{5.03}$   \n(10, Composite)              10         Composite  ${68.82}_{2.86}$   \n(10, AVG)                    10               AVG  ${68.96}_{1.71}$   \n(19, State Trk.)             19        State Trk.  ${91.01}_{3.03}$   \n(19, Fluent Trk.)            19       Fluent Trk.  ${73.26}_{4.77}$   \n(19, Action Exec.)           19      Action Exec.  ${62.86}_{4.72}$   \n(19, Effects)                19           Effects   ${69.57}_{4.8}$   \n(19, Num. Reas.)             19        Num. Reas.  ${56.99}_{5.13}$   \n(19, Composite)              19         Composite  ${65.57}_{2.88}$   \n(19, AVG)                    19               AVG  ${68.56}_{1.71}$   \n\n                    (llama_8b, FS-3) (llama_70b, FS-3)  \n(1, State Trk.)     ${71.95}_{4.96}$  ${89.29}_{3.37}$  \n(1, Fluent Trk.)    ${68.42}_{4.77}$  ${82.65}_{3.82}$  \n(1, Action Exec.)    ${84.31}_{3.6}$   ${93.14}_{2.5}$  \n(1, Effects)        ${73.91}_{4.58}$  ${69.89}_{4.76}$  \n(1, Num. Reas.)     ${56.76}_{5.76}$   ${56.1}_{5.48}$  \n(1, Composite)      ${58.37}_{3.23}$   ${74.3}_{2.77}$  \n(1, AVG)             ${67.26}_{1.8}$  ${77.26}_{1.58}$  \n(10, State Trk.)    ${64.18}_{5.86}$  ${86.11}_{4.08}$  \n(10, Fluent Trk.)   ${69.66}_{4.87}$  ${82.47}_{3.86}$  \n(10, Action Exec.)   ${63.0}_{4.83}$  ${74.76}_{4.28}$  \n(10, Effects)       ${53.68}_{5.12}$  ${65.31}_{4.81}$  \n(10, Num. Reas.)    ${42.25}_{5.86}$  ${46.88}_{5.09}$  \n(10, Composite)     ${60.43}_{3.19}$  ${61.98}_{2.99}$  \n(10, AVG)           ${59.51}_{1.92}$  ${67.35}_{1.74}$  \n(19, State Trk.)    ${63.64}_{5.13}$  ${84.27}_{3.86}$  \n(19, Fluent Trk.)   ${63.38}_{5.72}$  ${71.08}_{4.98}$  \n(19, Action Exec.)   ${54.55}_{5.0}$  ${62.86}_{4.72}$  \n(19, Effects)       ${56.63}_{5.44}$  ${66.67}_{4.89}$  \n(19, Num. Reas.)    ${49.15}_{6.51}$  ${48.39}_{5.18}$  \n(19, Composite)     ${57.31}_{3.11}$  ${62.04}_{2.93}$  \n(19, AVG)           ${57.58}_{1.93}$  ${64.72}_{1.76}$  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>plan pength</th>\n      <th>question category</th>\n      <th>(gpt-4o, FS-3)</th>\n      <th>(llama_8b, FS-3)</th>\n      <th>(llama_70b, FS-3)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(1, State Trk.)</th>\n      <td>1</td>\n      <td>State Trk.</td>\n      <td>${91.57}_{3.05}$</td>\n      <td>${71.95}_{4.96}$</td>\n      <td>${89.29}_{3.37}$</td>\n    </tr>\n    <tr>\n      <th>(1, Fluent Trk.)</th>\n      <td>1</td>\n      <td>Fluent Trk.</td>\n      <td>${85.0}_{3.57}$</td>\n      <td>${68.42}_{4.77}$</td>\n      <td>${82.65}_{3.82}$</td>\n    </tr>\n    <tr>\n      <th>(1, Action Exec.)</th>\n      <td>1</td>\n      <td>Action Exec.</td>\n      <td>${95.1}_{2.14}$</td>\n      <td>${84.31}_{3.6}$</td>\n      <td>${93.14}_{2.5}$</td>\n    </tr>\n    <tr>\n      <th>(1, Effects)</th>\n      <td>1</td>\n      <td>Effects</td>\n      <td>${74.19}_{4.54}$</td>\n      <td>${73.91}_{4.58}$</td>\n      <td>${69.89}_{4.76}$</td>\n    </tr>\n    <tr>\n      <th>(1, Num. Reas.)</th>\n      <td>1</td>\n      <td>Num. Reas.</td>\n      <td>${58.54}_{5.44}$</td>\n      <td>${56.76}_{5.76}$</td>\n      <td>${56.1}_{5.48}$</td>\n    </tr>\n    <tr>\n      <th>(1, Composite)</th>\n      <td>1</td>\n      <td>Composite</td>\n      <td>${82.66}_{2.4}$</td>\n      <td>${58.37}_{3.23}$</td>\n      <td>${74.3}_{2.77}$</td>\n    </tr>\n    <tr>\n      <th>(1, AVG)</th>\n      <td>1</td>\n      <td>AVG</td>\n      <td>${81.92}_{1.45}$</td>\n      <td>${67.26}_{1.8}$</td>\n      <td>${77.26}_{1.58}$</td>\n    </tr>\n    <tr>\n      <th>(10, State Trk.)</th>\n      <td>10</td>\n      <td>State Trk.</td>\n      <td>${91.55}_{3.3}$</td>\n      <td>${64.18}_{5.86}$</td>\n      <td>${86.11}_{4.08}$</td>\n    </tr>\n    <tr>\n      <th>(10, Fluent Trk.)</th>\n      <td>10</td>\n      <td>Fluent Trk.</td>\n      <td>${84.54}_{3.67}$</td>\n      <td>${69.66}_{4.87}$</td>\n      <td>${82.47}_{3.86}$</td>\n    </tr>\n    <tr>\n      <th>(10, Action Exec.)</th>\n      <td>10</td>\n      <td>Action Exec.</td>\n      <td>${73.79}_{4.33}$</td>\n      <td>${63.0}_{4.83}$</td>\n      <td>${74.76}_{4.28}$</td>\n    </tr>\n    <tr>\n      <th>(10, Effects)</th>\n      <td>10</td>\n      <td>Effects</td>\n      <td>${59.18}_{4.96}$</td>\n      <td>${53.68}_{5.12}$</td>\n      <td>${65.31}_{4.81}$</td>\n    </tr>\n    <tr>\n      <th>(10, Num. Reas.)</th>\n      <td>10</td>\n      <td>Num. Reas.</td>\n      <td>${41.67}_{5.03}$</td>\n      <td>${42.25}_{5.86}$</td>\n      <td>${46.88}_{5.09}$</td>\n    </tr>\n    <tr>\n      <th>(10, Composite)</th>\n      <td>10</td>\n      <td>Composite</td>\n      <td>${68.82}_{2.86}$</td>\n      <td>${60.43}_{3.19}$</td>\n      <td>${61.98}_{2.99}$</td>\n    </tr>\n    <tr>\n      <th>(10, AVG)</th>\n      <td>10</td>\n      <td>AVG</td>\n      <td>${68.96}_{1.71}$</td>\n      <td>${59.51}_{1.92}$</td>\n      <td>${67.35}_{1.74}$</td>\n    </tr>\n    <tr>\n      <th>(19, State Trk.)</th>\n      <td>19</td>\n      <td>State Trk.</td>\n      <td>${91.01}_{3.03}$</td>\n      <td>${63.64}_{5.13}$</td>\n      <td>${84.27}_{3.86}$</td>\n    </tr>\n    <tr>\n      <th>(19, Fluent Trk.)</th>\n      <td>19</td>\n      <td>Fluent Trk.</td>\n      <td>${73.26}_{4.77}$</td>\n      <td>${63.38}_{5.72}$</td>\n      <td>${71.08}_{4.98}$</td>\n    </tr>\n    <tr>\n      <th>(19, Action Exec.)</th>\n      <td>19</td>\n      <td>Action Exec.</td>\n      <td>${62.86}_{4.72}$</td>\n      <td>${54.55}_{5.0}$</td>\n      <td>${62.86}_{4.72}$</td>\n    </tr>\n    <tr>\n      <th>(19, Effects)</th>\n      <td>19</td>\n      <td>Effects</td>\n      <td>${69.57}_{4.8}$</td>\n      <td>${56.63}_{5.44}$</td>\n      <td>${66.67}_{4.89}$</td>\n    </tr>\n    <tr>\n      <th>(19, Num. Reas.)</th>\n      <td>19</td>\n      <td>Num. Reas.</td>\n      <td>${56.99}_{5.13}$</td>\n      <td>${49.15}_{6.51}$</td>\n      <td>${48.39}_{5.18}$</td>\n    </tr>\n    <tr>\n      <th>(19, Composite)</th>\n      <td>19</td>\n      <td>Composite</td>\n      <td>${65.57}_{2.88}$</td>\n      <td>${57.31}_{3.11}$</td>\n      <td>${62.04}_{2.93}$</td>\n    </tr>\n    <tr>\n      <th>(19, AVG)</th>\n      <td>19</td>\n      <td>AVG</td>\n      <td>${68.56}_{1.71}$</td>\n      <td>${57.58}_{1.93}$</td>\n      <td>${64.72}_{1.76}$</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = WITHOUT_RANDOM_SUB\n",
    "rams = WITHOUT_RAMIFICATIONS\n",
    "prompt_type = 'few_shot_3'#'zero_shot'\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for rams in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "df3 = to_df_by_len_by_category(stats_all, answer_type, prompt_type, model_names=model_names, subs=subs, ramifications=rams)\n",
    "df3\n",
    "        # # \n",
    "# caption_nl = f'performance of on the test set by categories, {subs}, {rams}'.replace('_', ' ')\n",
    "# save_key = f'by_plan_by_categories.{answer_type}.{prompt_type}.{subs}.{rams}'\n",
    "# \n",
    "# latex_table_all = latex_table_mods(to_latex_table(df3, caption_nl, label=save_key, index=False))\n",
    "# with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#     f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-02T03:20:42.727088Z",
     "start_time": "2024-10-02T03:20:42.678403Z"
    }
   },
   "id": "626bbb8dc5ce893a",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9ff6a8128a39bfce",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# By Few Shot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8ff84d5e11af818"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_names =  ['gpt-4o', 'gemini', 'llama2-13b-chat', 'llama-3-8b-instruct', 'llama2-7b-chat', 'gemma-7b']\n",
    "\n",
    "\n",
    "subs = WITHOUT_RANDOM_SUB\n",
    "rams = WITHOUT_RAMIFICATIONS\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for rams in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "df4 = to_df_few_shot(stats_all, answer_type,  model_names=model_names, subs=subs, ramifications=rams)\n",
    "df4\n",
    "caption_nl = f'performance of on the test set by few shots, {subs}, {rams}'.replace('_', ' ')\n",
    "save_key = f'by_few_shot.{subs}.{rams}'\n",
    "\n",
    "latex_table_all = latex_table_mods(to_latex_table(df4, caption_nl, label=save_key, index=False))\n",
    "with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "    f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4b65bba5fcdd5c0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf0ab3cad6f0bf55",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# By Few Shot by Category"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d35fbc030595bffb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_names =  ['gemini', 'llama2-13b-chat', 'gemma-7b']\n",
    "\n",
    "\n",
    "subs = WITHOUT_RANDOM_SUB\n",
    "rams = WITHOUT_RAMIFICATIONS\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for rams in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "df5 = to_df_few_shot_by_category(stats_all, answer_type,  model_names=model_names, subs=subs, ramifications=rams)\n",
    "# df5\n",
    "caption_nl = f'performance of on the test set by few shots, {subs}, {rams}'.replace('_', ' ')\n",
    "save_key = f'by_few_shot_by_category.{subs}.{rams}'\n",
    "\n",
    "latex_table_all = latex_table_mods(to_latex_table(df5, caption_nl, label=save_key, index=False))\n",
    "with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "    f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f84b90c4445ab17b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e446ca53ab66a885",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69fc534a6e77971d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

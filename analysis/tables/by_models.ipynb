{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('..')\n",
    "from common import *\n",
    "from analysis.model_performances import *\n",
    "from copy import deepcopy\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "\n",
    "CONF_KEY = 'sem'\n",
    "\n",
    "def latex_table_mods(latex_table):\n",
    "    return latex_table.replace('{lllllllllllll}','{l|ll|ll|ll|ll||ll|ll}').replace('${None}_{None}$', '---')\n",
    "\n",
    "model_names =  ['gpt-4o']#, 'gemini', 'llama2-13b-chat', 'llama-3-8b-instruct', 'llama2-7b-chat', 'gemma-7b'] + ['llama-3-8b-instruct-finetuned','gemma-7b-finetuned']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:40:36.383905Z",
     "start_time": "2024-09-29T02:40:31.942490Z"
    }
   },
   "id": "1581e9208ff09f8e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60480/60480 [00:00<00:00, 69417.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer_type = TRUE_FALSE_ANSWER_TYPE\n",
    "answer_type_ext = f'{answer_type}.{ACCURACY_SCORE_KEY}'\n",
    "\n",
    "\n",
    "# ids_file_name = 'dataset_ids.test.pruned'  # None\n",
    "# save_main_dir = f'{STATISTICS_PATH}.{ids_file_name}'\n",
    "save_main_dir = f'{STATISTICS_PATH}.trial_run3'\n",
    "stats_all = collect_stats_all(answer_type_ext, save_main_dir=save_main_dir)\n",
    "print(len(stats_all))\n",
    "plan_lengths = [1,10,19]\n",
    "\n",
    "save_dir = os.path.join(save_main_dir, 'tables', 'by_models')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:40:38.034870Z",
     "start_time": "2024-09-29T02:40:37.135096Z"
    }
   },
   "id": "8fb4feeb322b4ab0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def to_df_by_len_by_category(results_all, answer_type, prompt_type,\n",
    "                      model_names = PROMPT_MODEL_NAMES,\n",
    "                      ramifications = WITHOUT_RAMIFICATIONS,\n",
    "                      domain = ALL_DOMAINS_KEY, \n",
    "                      subs = WITHOUT_RANDOM_SUB):\n",
    "\n",
    "    index = []\n",
    "    data = []    \n",
    "    for plan_length in PLAN_LENGTHS:\n",
    "        for question_category in QUESTION_CATEGORIES+[ALL_QUESTION_CATEGORIES_KEY]:\n",
    "            index.append((plan_length, TO_PRETTY.get(question_category,question_category)))\n",
    "            # index.append('{}')\n",
    "            data_columns = {}\n",
    "            data_columns['plan pength'] = plan_length\n",
    "            data_columns['question category'] = TO_PRETTY.get(question_category,question_category)\n",
    "            for model_name in model_names:\n",
    "                res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "                if res_obj:\n",
    "                    mean = res_obj['result']\n",
    "                    sem = None\n",
    "                    if res_obj['result_other']:\n",
    "                        sem = res_obj['result_other'][CONF_KEY]\n",
    "                    not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                    final_res = (mean, sem, not_corrupted)\n",
    "                else:\n",
    "                    final_res = (None, None, None)\n",
    "                final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "                final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "                data_columns[(TO_PRETTY.get(model_name,model_name), TO_PRETTY.get(prompt_type,prompt_type))] = final_res\n",
    "            data.append(data_columns)\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def to_df_few_shot(results_all, answer_type, \n",
    "                   plan_length=19,\n",
    "                      model_names = PROMPT_MODEL_NAMES,\n",
    "                      ramifications = WITHOUT_RAMIFICATIONS,\n",
    "                   question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "                      domain = ALL_DOMAINS_KEY, \n",
    "                      subs = WITHOUT_RANDOM_SUB):\n",
    "\n",
    "    index = []\n",
    "    data = []    \n",
    "    for prompt_type in PROMPT_TYPES:\n",
    "        index.append(prompt_type)\n",
    "        data_columns = {}\n",
    "        data_columns['prompt'] = prompt_type\n",
    "        for model_name in model_names:\n",
    "            res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "            if res_obj:\n",
    "                mean = res_obj['result']\n",
    "                sem = None\n",
    "                if res_obj['result_other']:\n",
    "                    sem = res_obj['result_other'][CONF_KEY]\n",
    "                not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                final_res = (mean, sem, not_corrupted)\n",
    "            else:\n",
    "                final_res = (None, None, None)\n",
    "            final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "            final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "            data_columns[TO_PRETTY.get(model_name,model_name)] = final_res\n",
    "        data.append(data_columns)\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def to_df_few_shot_by_category(results_all, answer_type, \n",
    "                               plan_length=19, model_names = PROMPT_MODEL_NAMES,\n",
    "                      ramifications = WITHOUT_RAMIFICATIONS,\n",
    "                   question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "                      domain = ALL_DOMAINS_KEY, \n",
    "                      subs = WITHOUT_RANDOM_SUB):\n",
    "\n",
    "    data = []    \n",
    "    for question_category in QUESTION_CATEGORIES+[ALL_QUESTION_CATEGORIES_KEY]:\n",
    "        if question_category == 'composite':\n",
    "            continue\n",
    "        data_columns = {}\n",
    "        data_columns['question category'] = TO_PRETTY.get(question_category,question_category)\n",
    "        for model_name in model_names:\n",
    "            for prompt_type in  ['few_shot_0', 'few_shot_1', 'few_shot_5']:\n",
    "                res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "                if res_obj:\n",
    "                    mean = res_obj['result']\n",
    "                    sem = None\n",
    "                    if res_obj['result_other']:\n",
    "                        sem = res_obj['result_other'][CONF_KEY]\n",
    "                    not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                    final_res = (mean, sem, not_corrupted)\n",
    "                else:\n",
    "                    final_res = (None, None, None)\n",
    "                final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "                final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "                data_columns[(TO_PRETTY.get(model_name,model_name),prompt_type)] = final_res\n",
    "        data.append(data_columns)\n",
    "    return pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:40:38.824171Z",
     "start_time": "2024-09-29T02:40:38.802297Z"
    }
   },
   "id": "dd77fda858739d0e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def to_df(results_all, plan_lengths, answer_type, models=PROMPT_MODEL_NAMES,\n",
    "#           prompt_types = PROMPT_TYPES,\n",
    "#           domain = ALL_DOMAINS_KEY, subs = WITHOUT_RANDOM_SUB):\n",
    "#     \n",
    "#     index = []\n",
    "#     data = []    \n",
    "#     for plan_length in plan_lengths:\n",
    "#         for ramifications in RAMIFICATION_TYPES:\n",
    "#             index.append((plan_length, TO_PRETTY.get(ramifications, ramifications)))\n",
    "#             # data_columns = {}\n",
    "#             for model_name in models:\n",
    "#                 for prompt_type in prompt_types:\n",
    "#                     res_obj = filter_single_selector(results_all, plan_length, ALL_QUESTION_CATEGORIES_KEY, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "#                     # print(res_obj)\n",
    "#                     if res_obj:\n",
    "#                         mean = res_obj['result']\n",
    "#                         sem = None\n",
    "#                         if res_obj['result_other']:\n",
    "#                             sem = res_obj['result_other'][CONF_KEY]\n",
    "#                         not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "#                         final_res = (mean, sem, not_corrupted)\n",
    "#                     else:\n",
    "#                         final_res = (None, None, None)\n",
    "#                     final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "#                     final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "#                     data_columns[(TO_PRETTY.get(model_name, model_name), TO_PRETTY.get(prompt_type, prompt_type))] = final_res\n",
    "#             data.append(data_columns)\n",
    "#     return pd.DataFrame(data, index = index)\n",
    "# \n",
    "# def to_df_by_category(results_all, answer_type,  \n",
    "#                       model_names = PROMPT_MODEL_NAMES,\n",
    "#                       prompt_types= PROMPT_TYPES,\n",
    "#                       ramifications = WITHOUT_RAMIFICATIONS,\n",
    "#                       domain = ALL_DOMAINS_KEY, \n",
    "#                       subs = WITHOUT_RANDOM_SUB,\n",
    "#                       plan_length=19):\n",
    "# \n",
    "#     index = []\n",
    "#     data = []    \n",
    "#     for question_category in QUESTION_CATEGORIES:\n",
    "#         index.append(question_category)\n",
    "#         data_columns = {}\n",
    "#         for model_name in model_names:\n",
    "#             for prompt_type in prompt_types:\n",
    "#                 res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "#                 if res_obj:\n",
    "#                     mean = res_obj['result']\n",
    "#                     sem = None\n",
    "#                     if res_obj['result_other']:\n",
    "#                         sem = res_obj['result_other'][CONF_KEY]\n",
    "#                     not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "#                     final_res = (mean, sem, not_corrupted)\n",
    "#                 else:\n",
    "#                     final_res = (None, None, None)\n",
    "#                 final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "#                 final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "#                 data_columns[(TO_PRETTY.get(model_name,model_name), TO_PRETTY.get(prompt_type,prompt_type))] = final_res\n",
    "#         data.append(data_columns)\n",
    "#     return pd.DataFrame(data, index = index)\n",
    "\n",
    "# models_for_plot =  ['gemini', 'gpt-4o'] + ['llama2-13b-chat', 'llama-3-8b-instruct','gemma-7b'] + ['llama-3-8b-tuned','gemma-7b-tuned']\n",
    "# # model_prompts_combos = [('small-models', SMALL_MODELS, PROMPT_TYPES), ('big-models', BIG_MODELS, ['few_shot_1', 'few_shot_5'])]\n",
    "# model_prompts_combos = [('all-models', PROMPT_MODEL_NAMES, ['few_shot_1', 'few_shot_5'])]\n",
    "# \n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for model_save_name, model_names, prompt_types in model_prompts_combos:\n",
    "#         df = to_df(stats_all, plan_lengths, answer_type, prompt_types=prompt_types, models=model_names, subs=subs)\n",
    "#         print(df)\n",
    "#         \n",
    "#         caption_nl = f'performance of {model_save_name} on the test set, {subs}'.replace('_', ' ')\n",
    "#         latex_table = latex_table_mods(to_latex_table(df, caption_nl, label=model_save_name))\n",
    "#         save_key = f'all.{model_save_name}.{subs}'\n",
    "#         with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#             f.write(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:40:39.477777Z",
     "start_time": "2024-09-29T02:40:39.472319Z"
    }
   },
   "id": "5b5a15905194ac6a",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot By Category"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aad3ef5e3825084"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plan_length = 19\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for model_save_name, model_names, prompt_types in model_prompts_combos:\n",
    "#         df2 = to_df_by_category(stats_all, answer_type, model_names=model_names, prompt_types=prompt_types, subs=subs)\n",
    "#         print(df2)\n",
    "#         \n",
    "#         caption_nl = f'performance of {model_save_name} on the test set by categories, {subs}, pl-{plan_length}'\n",
    "#         save_key = f'by_categories.{model_save_name}.{subs}'\n",
    "#         \n",
    "#         latex_table_all = latex_table_mods(to_latex_table(df2, caption_nl, label=save_key))\n",
    "#         with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#             f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:40:40.438575Z",
     "start_time": "2024-09-29T02:40:40.435519Z"
    }
   },
   "id": "da82c99c16ce0495",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# By Category By Length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9267d96722ee7613"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                    plan pength question category (gpt-4o, zero_shot)\n(1, Fluent Trk.)              1       Fluent Trk.    ${92.04}_{2.55}$\n(1, State Trk.)               1        State Trk.    ${85.57}_{3.57}$\n(1, Action Exec.)             1      Action Exec.    ${95.71}_{1.59}$\n(1, Effects)                  1           Effects    ${76.92}_{3.52}$\n(1, Num. Reas.)               1        Num. Reas.    ${67.63}_{3.97}$\n(1, Composite)                1         Composite    ${75.71}_{2.96}$\n(1, AVG)                      1               AVG    ${81.62}_{1.32}$\n(10, Fluent Trk.)            10       Fluent Trk.    ${93.86}_{2.25}$\n(10, State Trk.)             10        State Trk.    ${81.37}_{3.85}$\n(10, Action Exec.)           10      Action Exec.     ${71.6}_{3.47}$\n(10, Effects)                10           Effects    ${68.09}_{3.93}$\n(10, Num. Reas.)             10        Num. Reas.    ${56.25}_{4.13}$\n(10, Composite)              10         Composite    ${82.19}_{2.59}$\n(10, AVG)                    10               AVG    ${75.14}_{1.45}$\n(19, Fluent Trk.)            19       Fluent Trk.    ${92.59}_{2.52}$\n(19, State Trk.)             19        State Trk.    ${89.22}_{3.07}$\n(19, Action Exec.)           19      Action Exec.     ${68.26}_{3.6}$\n(19, Effects)                19           Effects     ${69.4}_{3.98}$\n(19, Num. Reas.)             19        Num. Reas.    ${50.35}_{4.18}$\n(19, Composite)              19         Composite    ${81.82}_{2.54}$\n(19, AVG)                    19               AVG    ${74.46}_{1.47}$",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>plan pength</th>\n      <th>question category</th>\n      <th>(gpt-4o, zero_shot)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(1, Fluent Trk.)</th>\n      <td>1</td>\n      <td>Fluent Trk.</td>\n      <td>${92.04}_{2.55}$</td>\n    </tr>\n    <tr>\n      <th>(1, State Trk.)</th>\n      <td>1</td>\n      <td>State Trk.</td>\n      <td>${85.57}_{3.57}$</td>\n    </tr>\n    <tr>\n      <th>(1, Action Exec.)</th>\n      <td>1</td>\n      <td>Action Exec.</td>\n      <td>${95.71}_{1.59}$</td>\n    </tr>\n    <tr>\n      <th>(1, Effects)</th>\n      <td>1</td>\n      <td>Effects</td>\n      <td>${76.92}_{3.52}$</td>\n    </tr>\n    <tr>\n      <th>(1, Num. Reas.)</th>\n      <td>1</td>\n      <td>Num. Reas.</td>\n      <td>${67.63}_{3.97}$</td>\n    </tr>\n    <tr>\n      <th>(1, Composite)</th>\n      <td>1</td>\n      <td>Composite</td>\n      <td>${75.71}_{2.96}$</td>\n    </tr>\n    <tr>\n      <th>(1, AVG)</th>\n      <td>1</td>\n      <td>AVG</td>\n      <td>${81.62}_{1.32}$</td>\n    </tr>\n    <tr>\n      <th>(10, Fluent Trk.)</th>\n      <td>10</td>\n      <td>Fluent Trk.</td>\n      <td>${93.86}_{2.25}$</td>\n    </tr>\n    <tr>\n      <th>(10, State Trk.)</th>\n      <td>10</td>\n      <td>State Trk.</td>\n      <td>${81.37}_{3.85}$</td>\n    </tr>\n    <tr>\n      <th>(10, Action Exec.)</th>\n      <td>10</td>\n      <td>Action Exec.</td>\n      <td>${71.6}_{3.47}$</td>\n    </tr>\n    <tr>\n      <th>(10, Effects)</th>\n      <td>10</td>\n      <td>Effects</td>\n      <td>${68.09}_{3.93}$</td>\n    </tr>\n    <tr>\n      <th>(10, Num. Reas.)</th>\n      <td>10</td>\n      <td>Num. Reas.</td>\n      <td>${56.25}_{4.13}$</td>\n    </tr>\n    <tr>\n      <th>(10, Composite)</th>\n      <td>10</td>\n      <td>Composite</td>\n      <td>${82.19}_{2.59}$</td>\n    </tr>\n    <tr>\n      <th>(10, AVG)</th>\n      <td>10</td>\n      <td>AVG</td>\n      <td>${75.14}_{1.45}$</td>\n    </tr>\n    <tr>\n      <th>(19, Fluent Trk.)</th>\n      <td>19</td>\n      <td>Fluent Trk.</td>\n      <td>${92.59}_{2.52}$</td>\n    </tr>\n    <tr>\n      <th>(19, State Trk.)</th>\n      <td>19</td>\n      <td>State Trk.</td>\n      <td>${89.22}_{3.07}$</td>\n    </tr>\n    <tr>\n      <th>(19, Action Exec.)</th>\n      <td>19</td>\n      <td>Action Exec.</td>\n      <td>${68.26}_{3.6}$</td>\n    </tr>\n    <tr>\n      <th>(19, Effects)</th>\n      <td>19</td>\n      <td>Effects</td>\n      <td>${69.4}_{3.98}$</td>\n    </tr>\n    <tr>\n      <th>(19, Num. Reas.)</th>\n      <td>19</td>\n      <td>Num. Reas.</td>\n      <td>${50.35}_{4.18}$</td>\n    </tr>\n    <tr>\n      <th>(19, Composite)</th>\n      <td>19</td>\n      <td>Composite</td>\n      <td>${81.82}_{2.54}$</td>\n    </tr>\n    <tr>\n      <th>(19, AVG)</th>\n      <td>19</td>\n      <td>AVG</td>\n      <td>${74.46}_{1.47}$</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = WITHOUT_RANDOM_SUB\n",
    "rams = WITHOUT_RAMIFICATIONS\n",
    "prompt_type = 'zero_shot'\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for rams in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "df3 = to_df_by_len_by_category(stats_all, answer_type, prompt_type, model_names=model_names, subs=subs, ramifications=rams)\n",
    "df3\n",
    "        # # \n",
    "# caption_nl = f'performance of on the test set by categories, {subs}, {rams}'.replace('_', ' ')\n",
    "# save_key = f'by_plan_by_categories.{answer_type}.{prompt_type}.{subs}.{rams}'\n",
    "# \n",
    "# latex_table_all = latex_table_mods(to_latex_table(df3, caption_nl, label=save_key, index=False))\n",
    "# with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#     f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T02:40:41.918952Z",
     "start_time": "2024-09-29T02:40:41.879406Z"
    }
   },
   "id": "626bbb8dc5ce893a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T02:06:56.938143Z"
    }
   },
   "id": "9ff6a8128a39bfce",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# By Few Shot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8ff84d5e11af818"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_names =  ['gpt-4o', 'gemini', 'llama2-13b-chat', 'llama-3-8b-instruct', 'llama2-7b-chat', 'gemma-7b']\n",
    "\n",
    "\n",
    "subs = WITHOUT_RANDOM_SUB\n",
    "rams = WITHOUT_RAMIFICATIONS\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for rams in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "df4 = to_df_few_shot(stats_all, answer_type,  model_names=model_names, subs=subs, ramifications=rams)\n",
    "df4\n",
    "caption_nl = f'performance of on the test set by few shots, {subs}, {rams}'.replace('_', ' ')\n",
    "save_key = f'by_few_shot.{subs}.{rams}'\n",
    "\n",
    "latex_table_all = latex_table_mods(to_latex_table(df4, caption_nl, label=save_key, index=False))\n",
    "with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "    f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T02:06:56.964169Z"
    }
   },
   "id": "a4b65bba5fcdd5c0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T02:06:57.158904Z"
    }
   },
   "id": "cf0ab3cad6f0bf55",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# By Few Shot by Category"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d35fbc030595bffb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_names =  ['gemini', 'llama2-13b-chat', 'gemma-7b']\n",
    "\n",
    "\n",
    "subs = WITHOUT_RANDOM_SUB\n",
    "rams = WITHOUT_RAMIFICATIONS\n",
    "# for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#     for rams in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "df5 = to_df_few_shot_by_category(stats_all, answer_type,  model_names=model_names, subs=subs, ramifications=rams)\n",
    "# df5\n",
    "caption_nl = f'performance of on the test set by few shots, {subs}, {rams}'.replace('_', ' ')\n",
    "save_key = f'by_few_shot_by_category.{subs}.{rams}'\n",
    "\n",
    "latex_table_all = latex_table_mods(to_latex_table(df5, caption_nl, label=save_key, index=False))\n",
    "with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "    f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T02:06:57.171006Z"
    }
   },
   "id": "f84b90c4445ab17b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T02:06:57.224019Z"
    }
   },
   "id": "e446ca53ab66a885",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-09-29T02:06:57.240631Z"
    }
   },
   "id": "69fc534a6e77971d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('..')\n",
    "from common import *\n",
    "from analysis.model_performances import *\n",
    "from questions_construction.questions import *\n",
    "from copy import deepcopy\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "TO_PRETTY |= {(WITHOUT_RANDOM_SUB, WITHOUT_RAMIFICATIONS): 'Baseline', \n",
    "              (WITHOUT_RANDOM_SUB, WITH_RAMIFICATIONS): 'Baseline + R.',\n",
    "             (WITH_RANDOM_SUB, WITHOUT_RAMIFICATIONS): 'Obfus. Baseline',\n",
    "             (WITH_RANDOM_SUB, WITH_RAMIFICATIONS): 'Obfus. Baseline + R.',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T06:24:09.414491Z",
     "start_time": "2024-11-20T06:24:03.209177Z"
    }
   },
   "id": "1581e9208ff09f8e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:52:06.717100Z",
     "start_time": "2024-11-20T06:52:04.714772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "questions_by_id = {d[OUT_OBJ_ID]: d for d in open_jsonl(f'{DATA_PATH}/test_data.paraphrased.cleaned.jsonl')}\n",
    "override = True\n",
    "\n",
    "answer_type = TRUE_FALSE_ANSWER_TYPE\n",
    "answer_response_type = f'{answer_type}.{ACCURACY_SCORE_KEY}' #f'{TRUE_FALSE_ANSWER_TYPE}.{ACCURACY_SCORE_KEY}' #\n",
    "stats_save_dir = f'{STATISTICS_PATH}.trial_run.ED'\n",
    "\n",
    "\n",
    "substitution = WITHOUT_RANDOM_SUB\n",
    "ramification = WITHOUT_RAMIFICATIONS\n",
    "prompt_type = ZERO_SHOT_PROMPT_KEY #FEW_SHOT_3_PROMPT_KEY #\n",
    "models = ['gpt-4o', 'llama_8b','llama_70b', 'llama_8b.finetuned_tf']\n",
    "\n",
    "data_all = []\n",
    "for model_name in models:\n",
    "    model_results_dir = f'{PROJECT_PATH}/data/prompting_results/{ramification}/{prompt_type}/{model_name}.jsonl'\n",
    "    model_results = open_jsonl(model_results_dir)\n",
    "    data_all_inst = data_all_single_run(questions_by_id, model_results, substitution, ramification, model_name,prompt_type)\n",
    "    data_all.extend(data_all_inst)"
   ],
   "id": "ff4516a101f58a11",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T07:01:08.983557Z",
     "start_time": "2024-11-20T07:01:08.951272Z"
    }
   },
   "cell_type": "code",
   "source": "data_all[0]",
   "id": "79918e80d9fcb323",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': '784689cc-3f7c-4a22-824a-ffc0e4c90483',\n",
       " 'lebel': 'package p1 is in vehicle t1',\n",
       " 'prompt': '[DOMAIN DESCRIPTION]\\nLoading a package onto a truck or an airplane is only possible if both the package and the vehicle are at the same location. Once loaded, the package is no longer at the location but inside the vehicle. Unloading from a truck or airplane is only possible when the vehicle is at a location and the package is inside. Unloading transfers the package from the vehicle to the location. Driving a truck is only possible between locations within the same city, moving it from the source to the destination. Flying an airplane is possible when it is in a location, and flying moves it from the source to the destination.\\n\\n[INITIAL CONDITIONS]\\nInitially, Airport l0_0 is situated in city c0, while airport l0_1 is also located in city c0. Airport l1_0 is found in city c1. At airport l0_0, you can find object a0, and object p3 is also located there. Airport l0_1 is home to object t0, whereas airport l1_1 has object t1. City c1 encompasses airport l1_1. Additionally, object p0 is situated at airport l0_1, and both object p1 and object p2 are located at airport l1_1.\\n\\n[QUESTION]\\nGiven the initial condition, the following actions are scheduled to take place: at airport l1_1, package p2 is loaded onto truck t1, followed by the loading of package p1 onto truck t1 at the same airport, then truck t1 is driven from airport l1_1 to airport l1_0 in city c1, while in city c1, truck t0 is driven from airports l1_1 to l0_1, subsequently, package p1 is unloaded from truck t1 at airport l1_0, in city c0, truck t0 is driven from airports l0_1 to l0_0, then at airport l0_0, package p3 is loaded onto airplane a0, airplane a0 flies from airports l0_0 to l1_0, and finally, package p3 is unloaded from airplane a0 at airport l1_0 and loaded onto truck t1 at the same airport to reach the current state. What are the valid properties of the state that do not involve negations for p1 before the first infeasible action in the sequence? Write None if there are none.\\n\\nAnswer the above question in the following format:\\n\\n[REASON]\\n<Write your reasoning here>\\n\\n[ANSWER]\\n<Write the final answer here>\\n',\n",
       " 'response': '[REASON]\\nTo determine the valid properties of the state for package p1 before the first infeasible action in the sequence, we need to follow the sequence of actions step by step and identify any infeasibilities.\\n\\n1. **Initial State:**\\n   - Airport l0_0 (city c0): a0, p3\\n   - Airport l0_1 (city c0): t0, p0\\n   - Airport l1_0 (city c1): \\n   - Airport l1_1 (city c1): t1, p1, p2\\n\\n2. **Action Sequence:**\\n   - Load p2 onto truck t1 at airport l1_1: \\n     - Valid: p2 is at l1_1, t1 is at l1_1.\\n     - New state: t1 (l1_1, contains p2), p1 (l1_1), p2 (in t1)\\n   - Load p1 onto truck t1 at airport l1_1:\\n     - Valid: p1 is at l1_1, t1 is at l1_1.\\n     - New state: t1 (l1_1, contains p1, p2), p1 (in t1), p2 (in t1)\\n   - Drive truck t1 from l1_1 to l1_0:\\n     - Valid: t1 can drive within city c1.\\n     - New state: t1 (l1_0, contains p1, p2), p1 (in t1), p2 (in t1)\\n   - Drive truck t0 from l1_1 to l0_1:\\n     - Invalid: t0 is initially at l0_1 in city c0 and cannot drive to l1_1 in city c1.\\n     - First infeasible action identified.\\n\\nBefore the first infeasible action, the state of package p1 is as follows:\\n- p1 is loaded onto truck t1 at airport l1_1.\\n- Truck t1, containing p1, is driven to airport l1_0.\\n\\nThus, the valid properties of the state for p1 before the first infeasible action are:\\n- p1 is inside truck t1.\\n- Truck t1 is at airport l1_0.\\n\\n[ANSWER]\\np1 is inside truck t1.\\nTruck t1 is at airport l1_0.',\n",
       " 'model': 'gpt-4o',\n",
       " 'prompt_type': 'zero_shot',\n",
       " 'ramification_type': 'without_ramifications',\n",
       " 'substitution_type': 'without_random_sub',\n",
       " 'domain_name': 'logistics',\n",
       " 'instance_id': 'Instance_2',\n",
       " 'question_category': 'composite',\n",
       " 'question_name': 'iter_6_question_2',\n",
       " 'fluent_type': 'all_fluents',\n",
       " 'answer_type': 'free_answer',\n",
       " 'question': 'Given the initial condition, the following actions are planned to be performed: at airport l1_1, package p2 is loaded in truck t1, at airport l1_1, package p1 is loaded in truck t1, truck t1 is driven to airport l1_0 from airport l1_1 in city c1, in city c1, truck t0 is driven from airports l1_1 to l0_1, from truck t1 package p1 is unloaded at airport l1_0, in city c0, truck t0 is driven from airports l0_1 to l0_0, at airport l0_0, package p3 is loaded in airplane a0, airplane a0 flies from airports l0_0 to l1_0, from airplane a0 package p3 is unloaded at airport l1_0 and package p3 is loaded in truck t1 at airport l1_0 to reach the current state. What are the valid properties of the state that do not involve negations for p1 before the first infeasible action in the sequence? Write None if there are none',\n",
       " 'answer': 'package p1 is in vehicle t1',\n",
       " 'plan_length': 10,\n",
       " 'initial_state_nl': 'Airport l0_0 is in city c0, airport l0_1 is located in city c0, airport l1_0 is in city c1, at airport l0_0, object a0 is located, at airport l0_0, object p3 is located, at airport l0_1, object t0 is located, at airport l1_1, object t1 is located, city c1 contains airport l1_1, object p0 is located at airport l0_1, object p1 is at airport l1_1 and object p2 is at airport l1_1.',\n",
       " 'fluent_sign_question': 'pos_neg',\n",
       " 'question_subcategories': ['fluent_tracking',\n",
       "  'action_executability',\n",
       "  'object_tracking'],\n",
       " 'question_paraphrased': 'Given the initial condition, the following actions are scheduled to take place: at airport l1_1, package p2 is loaded onto truck t1, followed by the loading of package p1 onto truck t1 at the same airport, then truck t1 is driven from airport l1_1 to airport l1_0 in city c1, while in city c1, truck t0 is driven from airports l1_1 to l0_1, subsequently, package p1 is unloaded from truck t1 at airport l1_0, in city c0, truck t0 is driven from airports l0_1 to l0_0, then at airport l0_0, package p3 is loaded onto airplane a0, airplane a0 flies from airports l0_0 to l1_0, and finally, package p3 is unloaded from airplane a0 at airport l1_0 and loaded onto truck t1 at the same airport to reach the current state. What are the valid properties of the state that do not involve negations for p1 before the first infeasible action in the sequence? Write None if there are none.',\n",
       " 'initial_state_nl_paraphrased': 'Airport l0_0 is situated in city c0, while airport l0_1 is also located in city c0. Airport l1_0 is found in city c1. At airport l0_0, you can find object a0, and object p3 is also located there. Airport l0_1 is home to object t0, whereas airport l1_1 has object t1. City c1 encompasses airport l1_1. Additionally, object p0 is situated at airport l0_1, and both object p1 and object p2 are located at airport l1_1.',\n",
       " 'unique_id': '784689cc-3f7c-4a22-824a-ffc0e4c90483::gpt-4o::zero_shot::without_ramifications::without_random_sub'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "source": [
    "def to_df_by_models(data_all, prompt_type,models, ramifications, subs,\n",
    "                      score_type=ACCURACY_SCORE_KEY, \n",
    "                      question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "                      domain = ALL_DOMAINS_KEY,\n",
    "                      answer_type=TRUE_FALSE_ANSWER_TYPE,\n",
    "                      plan_length=19):\n",
    "\n",
    "    # index = []\n",
    "    data_for_df = []    \n",
    "    for fluent_type in FLUENT_TYPES_LIST:\n",
    "        # index.append()\n",
    "        data_columns = {}\n",
    "        data_columns['fluent type'] = TO_PRETTY[fluent_type]\n",
    "        for model in models:\n",
    "            data = filter_multi_selector_modified(data_all, ramifications, model, prompt_type, answer_type, subs, plan_length, [(OUT_OBJ_FLUENT_TYPE, {fluent_type})])\n",
    "            stats = TrueFalseStatsCustom(data, plan_length, question_category, ramifications, model, prompt_type, domain, subs, score_type=score_type)\n",
    "            res_obj = stats.compute()\n",
    "            if res_obj:\n",
    "                mean = res_obj['result']\n",
    "                sem = None\n",
    "                if res_obj['result_other']:\n",
    "                    sem = res_obj['result_other']['sem']\n",
    "                final_res = (mean, sem)\n",
    "            else:\n",
    "                final_res = (None, None)\n",
    "            final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "            final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "            # print(final_res)\n",
    "            data_columns[TO_PRETTY.get(model, model)] = final_res\n",
    "        data_for_df.append(data_columns)\n",
    "    return pd.DataFrame(data_for_df)\n",
    "\n",
    "def to_df_by_models_sign(data_all, prompt_type,models, ramifications, subs,\n",
    "                      score_type=ACCURACY_SCORE_KEY, \n",
    "                      question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "                      domain = ALL_DOMAINS_KEY,\n",
    "                      answer_type=TRUE_FALSE_ANSWER_TYPE,\n",
    "                      plan_length=19):\n",
    "\n",
    "    # index = []\n",
    "    data_for_df = []    \n",
    "    for fluent_sign in POS_NEG_FLUENTS_KEY_LIST:\n",
    "        # index.append()\n",
    "        data_columns = {}\n",
    "        data_columns['fluent sign'] = fluent_sign\n",
    "        for model in models:\n",
    "            data = filter_multi_selector_modified(data_all, ramifications, model, prompt_type, answer_type, subs, plan_length, [(OUT_OBJ_FLUENT_SIGN_QUESTION, {fluent_sign})])\n",
    "            stats = TrueFalseStatsCustom(data, plan_length, question_category, ramifications, model, prompt_type, domain, subs, score_type=score_type)\n",
    "            res_obj = stats.compute()\n",
    "            if res_obj:\n",
    "                mean = res_obj['result']\n",
    "                sem = None\n",
    "                if res_obj['result_other']:\n",
    "                    sem = res_obj['result_other']['sem']\n",
    "                final_res = (mean, sem)\n",
    "            else:\n",
    "                final_res = (None, None)\n",
    "            final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "            final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "            # print(final_res)\n",
    "            data_columns[TO_PRETTY.get(model, model)] = final_res\n",
    "        data_for_df.append(data_columns)\n",
    "    return pd.DataFrame(data_for_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T07:10:34.361108Z",
     "start_time": "2024-11-20T07:10:34.346588Z"
    }
   },
   "id": "dd77fda858739d0e",
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "source": [
    "# def to_df_by_sub_ram_neg_pos(data_all, model_name, prompt_type,\n",
    "#                       score_type=ACCURACY_SCORE_KEY, \n",
    "#                       question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "#                       domain = ALL_DOMAINS_KEY,\n",
    "#                       answer_type=TRUE_FALSE_ANSWER_TYPE,\n",
    "#                       plan_length=19):\n",
    "# \n",
    "#     # index = []\n",
    "#     data_for_df = []    \n",
    "#     for is_pos_fluent in [True, False]:\n",
    "#         # index.append()\n",
    "#         data_columns = {}\n",
    "#         data_columns['fluent type'] = is_pos_fluent\n",
    "#         for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#             for ramifications in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "#                 data = filter_multi_selector_modified(data_all, ramifications, model_name, prompt_type, answer_type, subs, plan_length, [(OUT_OBJ_IS_POS_FLUENT_QUESTION, {is_pos_fluent})])\n",
    "#                 stats = TrueFalseStatsCustom(data, plan_length, question_category, ramifications, model_name, prompt_type, domain, subs, score_type=score_type)\n",
    "#                 res_obj = stats.compute()\n",
    "#                 if res_obj:\n",
    "#                     mean = res_obj['result']\n",
    "#                     sem = None\n",
    "#                     if res_obj['result_other']:\n",
    "#                         sem = res_obj['result_other']['sem']\n",
    "#                     not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "#                     final_res = (mean, sem, not_corrupted)\n",
    "#                 else:\n",
    "#                     final_res = (None, None, None)\n",
    "#                 final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "#                 final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "#                 # print(final_res)\n",
    "#                 data_columns[TO_PRETTY[(subs, ramifications)]] = final_res\n",
    "#         data_for_df.append(data_columns)\n",
    "#     return pd.DataFrame(data_for_df)\n",
    "# \n",
    "# def to_df_by_sub_ram_all(data_all, model_name, prompt_type,\n",
    "#                       score_type=ACCURACY_SCORE_KEY, \n",
    "#                       question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "#                       domain = ALL_DOMAINS_KEY,\n",
    "#                       answer_type=TRUE_FALSE_ANSWER_TYPE,\n",
    "#                       plan_length=19):\n",
    "# \n",
    "#     # index = []\n",
    "#     data_for_df = []    \n",
    "#     for fluent_type in FLUENT_TYPES_LIST:\n",
    "#         # index.append()\n",
    "#         data_columns = {}\n",
    "#         data_columns['fluent type'] = TO_PRETTY[fluent_type]\n",
    "#         for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "#             for ramifications in [WITHOUT_RAMIFICATIONS]: #WITH_RAMIFICATIONS\n",
    "#                 data = filter_multi_selector_modified(data_all, ramifications, model_name, prompt_type, answer_type, subs, plan_length, [(OUT_OBJ_FLUENT_TYPE, {fluent_type})])\n",
    "#                 stats = TrueFalseStatsCustom(data, plan_length, question_category, ramifications, model_name, prompt_type, domain, subs, score_type=score_type)\n",
    "#                 res_obj = stats.compute()\n",
    "#                 if res_obj:\n",
    "#                     mean = res_obj['result']\n",
    "#                     sem = None\n",
    "#                     if res_obj['result_other']:\n",
    "#                         sem = res_obj['result_other']['sem']\n",
    "#                     not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "#                     final_res = (mean, sem, not_corrupted)\n",
    "#                 else:\n",
    "#                     final_res = (None, None, None)\n",
    "#                 final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "#                 final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "#                 # print(final_res)\n",
    "#                 data_columns[TO_PRETTY[(subs, ramifications)]] = final_res\n",
    "#         data_for_df.append(data_columns)\n",
    "#     return pd.DataFrame(data_for_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T07:10:35.204633Z",
     "start_time": "2024-11-20T07:10:35.197962Z"
    }
   },
   "id": "3a77663155cb1eb8",
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subs and Ramfications"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aad3ef5e3825084"
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T07:10:37.434356Z",
     "start_time": "2024-11-20T07:10:36.448877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plan_length = 19\n",
    "df = to_df_by_models_sign(data_all, prompt_type, models, ramification, substitution, answer_type = answer_type, plan_length=plan_length)\n",
    "df\n",
    "        \n",
    "# caption_nl = f'performance of {model_name}, {prompt_type}, pl-{plan_length}'.replace('_', ' ')\n",
    "# save_key = f'{model_name}.{prompt_type}.{plan_length}'\n",
    "# \n",
    "# latex_table_all = to_latex_table(df, caption_nl, label=save_key, index=False)\n",
    "# with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#     f.write(latex_table_all)"
   ],
   "id": "da82c99c16ce0495",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  fluent sign            gpt-4o          llama_8b         llama_70b  \\\n",
       "0         pos   ${77.48}_{3.4}$  ${72.86}_{5.32}$  ${76.99}_{3.96}$   \n",
       "1         neg  ${73.85}_{3.85}$  ${58.21}_{6.03}$  ${71.31}_{4.09}$   \n",
       "2     pos_neg  ${73.84}_{1.79}$   ${57.1}_{2.81}$  ${69.61}_{1.93}$   \n",
       "\n",
       "  llama_8b.finetuned_tf  \n",
       "0       ${85.6}_{3.14}$  \n",
       "1      ${77.19}_{3.93}$  \n",
       "2       ${88.5}_{1.27}$  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fluent sign</th>\n",
       "      <th>gpt-4o</th>\n",
       "      <th>llama_8b</th>\n",
       "      <th>llama_70b</th>\n",
       "      <th>llama_8b.finetuned_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>${77.48}_{3.4}$</td>\n",
       "      <td>${72.86}_{5.32}$</td>\n",
       "      <td>${76.99}_{3.96}$</td>\n",
       "      <td>${85.6}_{3.14}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>${73.85}_{3.85}$</td>\n",
       "      <td>${58.21}_{6.03}$</td>\n",
       "      <td>${71.31}_{4.09}$</td>\n",
       "      <td>${77.19}_{3.93}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos_neg</td>\n",
       "      <td>${73.84}_{1.79}$</td>\n",
       "      <td>${57.1}_{2.81}$</td>\n",
       "      <td>${69.61}_{1.93}$</td>\n",
       "      <td>${88.5}_{1.27}$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T07:10:54.203883Z",
     "start_time": "2024-11-20T07:10:54.178860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latex_table_all = to_latex_table(df, 'some caption', index=False)\n",
    "print(latex_table_all)"
   ],
   "id": "b6b0cbdd30bc9a19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\begin{adjustbox}{width=\\textwidth,center}\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "fluent sign &           gpt-4o &         llama_8b &        llama_70b & llama_8b.finetuned_tf \\\\\n",
      "\\midrule\n",
      "        pos &  ${77.48}_{3.4}$ & ${72.86}_{5.32}$ & ${76.99}_{3.96}$ &       ${85.6}_{3.14}$ \\\\\n",
      "        neg & ${73.85}_{3.85}$ & ${58.21}_{6.03}$ & ${71.31}_{4.09}$ &      ${77.19}_{3.93}$ \\\\\n",
      "    pos_neg & ${73.84}_{1.79}$ &  ${57.1}_{2.81}$ & ${69.61}_{1.93}$ &       ${88.5}_{1.27}$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\end{adjustbox}\n",
      "\\caption{some caption}\n",
      "\\label{table:}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paveldolin/dev/research/completed/reasoning_about_actions/pipeline/src/analysis/tables/helpers.py:45: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=index, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "source": [
    "df_pos_neg = to_df_by_sub_ram_neg_pos(data_all, model_name, prompt_type, plan_length=plan_length)\n",
    "df_pos_neg\n",
    "        \n",
    "# caption_nl = f'performance of {model_name}, {prompt_type}, pl-{plan_length}'.replace('_', ' ')\n",
    "# save_key = f'{model_name}.{prompt_type}.{plan_length}'\n",
    "# \n",
    "# latex_table_all = to_latex_table(df, caption_nl, label=save_key, index=False)\n",
    "# with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "#     f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T06:47:32.219385Z",
     "start_time": "2024-11-20T06:47:32.172911Z"
    }
   },
   "id": "a2a6c92185f6a2e3",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OUT_OBJ_IS_POS_FLUENT_QUESTION' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [80]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df_pos_neg \u001B[38;5;241m=\u001B[39m \u001B[43mto_df_by_sub_ram_neg_pos\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_all\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplan_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplan_length\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m df_pos_neg\n",
      "Input \u001B[0;32mIn [78]\u001B[0m, in \u001B[0;36mto_df_by_sub_ram_neg_pos\u001B[0;34m(data_all, model_name, prompt_type, score_type, question_category, domain, answer_type, plan_length)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m subs \u001B[38;5;129;01min\u001B[39;00m [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ramifications \u001B[38;5;129;01min\u001B[39;00m [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n\u001B[0;32m---> 16\u001B[0m         data \u001B[38;5;241m=\u001B[39m filter_multi_selector_modified(data_all, ramifications, model_name, prompt_type, answer_type, subs, plan_length, [(\u001B[43mOUT_OBJ_IS_POS_FLUENT_QUESTION\u001B[49m, {is_pos_fluent})])\n\u001B[1;32m     17\u001B[0m         stats \u001B[38;5;241m=\u001B[39m TrueFalseStatsCustom(data, plan_length, question_category, ramifications, model_name, prompt_type, domain, subs, score_type\u001B[38;5;241m=\u001B[39mscore_type)\n\u001B[1;32m     18\u001B[0m         res_obj \u001B[38;5;241m=\u001B[39m stats\u001B[38;5;241m.\u001B[39mcompute()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'OUT_OBJ_IS_POS_FLUENT_QUESTION' is not defined"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "source": [
    "# By Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9896e750372f819e"
  },
  {
   "cell_type": "code",
   "source": [
    "score_type=ACCURACY_SCORE_KEY, \n",
    "question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "domain = ALL_DOMAINS_KEY,\n",
    "answer_type=TRUE_FALSE_ANSWER_TYPE,\n",
    "plan_length=1\n",
    "\n",
    "data_for_df = []    \n",
    "for fluent_type in FLUENT_TYPES_LIST:\n",
    "    # index.append()\n",
    "    data_columns = {}\n",
    "    data_columns['fluent type'] = TO_PRETTY[fluent_type]\n",
    "    for model in models:\n",
    "        data = filter_multi_selector_modified(data_all, ramification, model, prompt_type, answer_type, substitution, plan_length, [(OUT_OBJ_FLUENT_TYPE, {fluent_type})])\n",
    "        print(len(data))\n",
    "        stats = TrueFalseStatsCustom(data, plan_length, question_category, ramification, model, prompt_type, domain, substitution, score_type=score_type)\n",
    "        res_obj = stats.compute()\n",
    "        if res_obj:\n",
    "            mean = res_obj['result']\n",
    "            sem = None\n",
    "            if res_obj['result_other']:\n",
    "                sem = res_obj['result_other']['sem']\n",
    "            final_res = (mean, sem)\n",
    "        else:\n",
    "            final_res = (None, None)\n",
    "        final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "        final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "        # print(final_res)\n",
    "        data_columns[TO_PRETTY.get(model, model)] = final_res\n",
    "    data_for_df.append(data_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-20T06:40:44.763603Z",
     "start_time": "2024-11-20T06:40:44.670001Z"
    }
   },
   "id": "f5a86ce0268bbed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:45:05.320630Z",
     "start_time": "2024-11-20T06:45:05.302489Z"
    }
   },
   "cell_type": "code",
   "source": "data = filter_multi_selector_modified(data_all, ramification, 'llama_8b', prompt_type, 'free_answer', substitution, 1, [(OUT_OBJ_FLUENT_TYPE, {fluent_type})])",
   "id": "4f5eb98e94bbf763",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:45:06.605467Z",
     "start_time": "2024-11-20T06:45:06.599796Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "d5a56939d3a52596",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:33:06.946940Z",
     "start_time": "2024-11-20T06:33:06.941696Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_type",
   "id": "b914aaf0385d3bcf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zero_shot'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:41:41.258452Z",
     "start_time": "2024-11-20T06:41:41.254560Z"
    }
   },
   "cell_type": "code",
   "source": "prompt_type",
   "id": "6d8534fe3b93dad2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zero_shot'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:41:50.847571Z",
     "start_time": "2024-11-20T06:41:50.842945Z"
    }
   },
   "cell_type": "code",
   "source": "substitution",
   "id": "b96ac014cf15e22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'without_random_sub'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T06:42:01.828974Z",
     "start_time": "2024-11-20T06:42:01.823347Z"
    }
   },
   "cell_type": "code",
   "source": "data_all[0]",
   "id": "c28b3db37fcf6ef5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': '784689cc-3f7c-4a22-824a-ffc0e4c90483',\n",
       " 'domain_name': 'logistics',\n",
       " 'instance_id': 'Instance_2',\n",
       " 'question_category': 'composite',\n",
       " 'question_name': 'iter_6_question_2',\n",
       " 'fluent_type': 'all_fluents',\n",
       " 'answer_type': 'free_answer',\n",
       " 'question': 'Given the initial condition, the following actions are planned to be performed: at airport l1_1, package p2 is loaded in truck t1, at airport l1_1, package p1 is loaded in truck t1, truck t1 is driven to airport l1_0 from airport l1_1 in city c1, in city c1, truck t0 is driven from airports l1_1 to l0_1, from truck t1 package p1 is unloaded at airport l1_0, in city c0, truck t0 is driven from airports l0_1 to l0_0, at airport l0_0, package p3 is loaded in airplane a0, airplane a0 flies from airports l0_0 to l1_0, from airplane a0 package p3 is unloaded at airport l1_0 and package p3 is loaded in truck t1 at airport l1_0 to reach the current state. What are the valid properties of the state that do not involve negations for p1 before the first infeasible action in the sequence? Write None if there are none',\n",
       " 'answer': 'package p1 is in vehicle t1',\n",
       " 'plan_length': 10,\n",
       " 'initial_state_nl': 'Airport l0_0 is in city c0, airport l0_1 is located in city c0, airport l1_0 is in city c1, at airport l0_0, object a0 is located, at airport l0_0, object p3 is located, at airport l0_1, object t0 is located, at airport l1_1, object t1 is located, city c1 contains airport l1_1, object p0 is located at airport l0_1, object p1 is at airport l1_1 and object p2 is at airport l1_1.',\n",
       " 'fluent_sign_question': 'pos_neg',\n",
       " 'question_subcategories': ['fluent_tracking',\n",
       "  'action_executability',\n",
       "  'object_tracking'],\n",
       " 'question_paraphrased': 'Given the initial condition, the following actions are scheduled to take place: at airport l1_1, package p2 is loaded onto truck t1, followed by the loading of package p1 onto truck t1 at the same airport, then truck t1 is driven from airport l1_1 to airport l1_0 in city c1, while in city c1, truck t0 is driven from airports l1_1 to l0_1, subsequently, package p1 is unloaded from truck t1 at airport l1_0, in city c0, truck t0 is driven from airports l0_1 to l0_0, then at airport l0_0, package p3 is loaded onto airplane a0, airplane a0 flies from airports l0_0 to l1_0, and finally, package p3 is unloaded from airplane a0 at airport l1_0 and loaded onto truck t1 at the same airport to reach the current state. What are the valid properties of the state that do not involve negations for p1 before the first infeasible action in the sequence? Write None if there are none.',\n",
       " 'initial_state_nl_paraphrased': 'Airport l0_0 is situated in city c0, while airport l0_1 is also located in city c0. Airport l1_0 is found in city c1. At airport l0_0, you can find object a0, and object p3 is also located there. Airport l0_1 is home to object t0, whereas airport l1_1 has object t1. City c1 encompasses airport l1_1. Additionally, object p0 is situated at airport l0_1, and both object p1 and object p2 are located at airport l1_1.',\n",
       " 'response': '[REASON]\\nBased on the initial conditions and the given sequence of actions, we can analyze the state of objects and locations at each step. We are looking for valid properties that do not involve negations for object p1 before the first infeasible action.\\n\\n1. Initially, p1 is at airport l1_1.\\n2. Then, p2 is loaded onto truck t1 at airport l1_1, but this does not affect p1.\\n3. Next, p1 is loaded onto truck t1 at airport l1_1, so p1 is now inside truck t1 at airport l1_1.\\n4. After that, truck t1 is driven from airport l1_1 to airport l1_0 in city c1. This means p1 is inside truck t1 at airport l1_0.\\n5. Then, truck t0 is driven from airport l1_1 to airport l0_1 in city c1, but this does not affect p1.\\n6. Next, p1 is unloaded from truck t1 at airport l1_0. This means p1 is no longer inside truck t1 but is at airport l1_0.\\n7. After that, truck t0 is driven from airport l0_1 to airport l0_0 in city c0, but this does not affect p1.\\n8. Finally, package p3 is loaded onto airplane a0 at airport l0_0, and then airplane a0 flies from airport l0_0 to airport l1_0. This action is the first infeasible action in the sequence because p3 is already at airport l1_0.\\n\\n[ANSWER]\\np1 is at airport l1_0.',\n",
       " 'response_clean': 'p1 is at airport l1_0.',\n",
       " 'evaluated_free_answer_response': '[Reasoning for the evaluation]\\nThe LLM response states that p1 is at airport l1_0, but the Ground Truth states that package p1 is in vehicle t1. These are two different locations, and there is no information in the Ground Truth that indicates the location of vehicle t1.\\n\\n[Answer]\\nFalse',\n",
       " 'model': 'llama_8b',\n",
       " 'prompt_type': 'zero_shot',\n",
       " 'ramification_type': 'without_ramifications',\n",
       " 'substitution_type': 'without_random_sub',\n",
       " 'unique_id': '784689cc-3f7c-4a22-824a-ffc0e4c90483::llama_8b::zero_shot::without_ramifications::without_random_sub'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "53bcf9d8cd36d49c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

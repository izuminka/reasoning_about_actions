{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('..')\n",
    "from src.common import *\n",
    "from src.analysis.model_performances import *\n",
    "from src.questions_construction.questions import *\n",
    "from copy import deepcopy\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "TO_PRETTY |= {(WITHOUT_RANDOM_SUB, WITHOUT_RAMIFICATIONS): 'Baseline', \n",
    "              (WITHOUT_RANDOM_SUB, WITH_RAMIFICATIONS): 'Baseline + R.',\n",
    "             (WITH_RANDOM_SUB, WITHOUT_RAMIFICATIONS): 'Obfus. Baseline',\n",
    "             (WITH_RANDOM_SUB, WITH_RAMIFICATIONS): 'Obfus. Baseline + R.',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T12:05:25.587329Z",
     "start_time": "2024-06-03T12:05:25.580191Z"
    }
   },
   "id": "1581e9208ff09f8e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions gathered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1040/1040 [00:43<00:00, 23.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is gathered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "questions_dir = f'{DATA_PATH}/questions_m1'\n",
    "questions_by_id = gather_questions(questions_dir)\n",
    "# sanity_checks()\n",
    "\n",
    "def gather_data_iterator():\n",
    "    for substitutions in SUBSTITUTION_TYPES:\n",
    "        for ramifications in RAMIFICATION_TYPES:\n",
    "            for model_name in ['gemini', 'gpt-4o']:\n",
    "                for prompt_type in ['few_shot_1']:\n",
    "                    yield substitutions, ramifications, model_name, prompt_type\n",
    "\n",
    "ids_file_name = f'dataset_ids.test.pruned' #'small_questions_ids' #\n",
    "if ids_file_name:\n",
    "    selected_ids = open_jsonl(f'{DATA_PATH}/{ids_file_name}.jsonl')\n",
    "    data_all, missing_data = gather_data(questions_by_id, selected_ids=selected_ids, iterator=gather_data_iterator)\n",
    "    save_main_dir = f'{STATISTICS_PATH}.{ids_file_name}'\n",
    "else:\n",
    "    data_all, missing_data = gather_data(questions_by_id)\n",
    "    save_main_dir = STATISTICS_PATH\n",
    "\n",
    "save_dir = os.path.join(save_main_dir, 'tables', 'by_fluents')\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T12:23:00.049835Z",
     "start_time": "2024-06-03T12:21:50.603049Z"
    }
   },
   "id": "8fb4feeb322b4ab0",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_df_by_category(data_all, model_name, prompt_type,\n",
    "                      score_type=ACCURACY_SCORE_KEY, \n",
    "                      question_category = ALL_QUESTION_CATEGORIES_KEY,\n",
    "                      domain = ALL_DOMAINS_KEY,\n",
    "                      answer_type=TRUE_FALSE_ANSWER_TYPE,\n",
    "                      plan_length=19):\n",
    "\n",
    "    # index = []\n",
    "    data_for_df = []    \n",
    "    for fluent_type in FLUENT_TYPES_LIST:\n",
    "        # index.append()\n",
    "        data_columns = {}\n",
    "        data_columns['fluent type'] = TO_PRETTY[fluent_type]\n",
    "        for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "            for ramifications in [WITHOUT_RAMIFICATIONS, WITH_RAMIFICATIONS]:\n",
    "                data = filter_multi_selector_modified(data_all, ramifications, model_name, prompt_type, answer_type, subs, plan_length, [(OUT_OBJ_FLUENT_TYPE, {fluent_type})])\n",
    "                stats = TrueFalseStatsCustom(data, plan_length, question_category, ramifications, model_name, prompt_type, domain, subs, score_type=score_type)\n",
    "                res_obj = stats.compute()\n",
    "                if res_obj:\n",
    "                    mean = res_obj['result']\n",
    "                    sem = None\n",
    "                    if res_obj['result_other']:\n",
    "                        sem = res_obj['result_other']['sem']\n",
    "                    not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                    final_res = (mean, sem, not_corrupted)\n",
    "                else:\n",
    "                    final_res = (None, None, None)\n",
    "                final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "                final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "                # print(final_res)\n",
    "                data_columns[TO_PRETTY[(subs, ramifications)]] = final_res\n",
    "        data_for_df.append(data_columns)\n",
    "    return pd.DataFrame(data_for_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T12:23:36.841445Z",
     "start_time": "2024-06-03T12:23:36.830090Z"
    }
   },
   "id": "dd77fda858739d0e",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Subs and Ramfications"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aad3ef5e3825084"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paveldolin/dev/research/current/reasoning_about_actions/pipeline/src/analysis/tables/helpers.py:45: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=index, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)\n"
     ]
    }
   ],
   "source": [
    "plan_length = 19\n",
    "model_name = 'gpt-4o' #'gemini' \n",
    "prompt_type = 'few_shot_1'\n",
    "df = to_df_by_category(data_all, model_name, prompt_type, plan_length=plan_length)\n",
    "df\n",
    "        \n",
    "caption_nl = f'performance of {model_name}, {prompt_type}, pl-{plan_length}'.replace('_', ' ')\n",
    "save_key = f'{model_name}.{prompt_type}.{plan_length}'\n",
    "\n",
    "latex_table_all = to_latex_table(df, caption_nl, label=save_key, index=False)\n",
    "with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "    f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T12:27:31.538035Z",
     "start_time": "2024-06-03T12:27:30.493994Z"
    }
   },
   "id": "da82c99c16ce0495",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c3ebc2ed2c060645"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

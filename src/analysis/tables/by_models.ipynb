{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('..')\n",
    "from src.common import *\n",
    "from src.analysis.model_performances import *\n",
    "from copy import deepcopy\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def latex_table_mods(latex_table):\n",
    "    return latex_table.replace('{lllllllllllll}','{l|ll|ll|ll|ll||ll|ll}').replace('${None}_{None}$', '---')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T00:17:16.937820Z",
     "start_time": "2024-05-29T00:17:16.851235Z"
    }
   },
   "id": "1581e9208ff09f8e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27648/27648 [00:04<00:00, 6388.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16721\n"
     ]
    }
   ],
   "source": [
    "answer_type = TRUE_FALSE_ANSWER_TYPE #FREE_ANSWER#\n",
    "score_key = ACCURACY_SCORE_KEY #F1_SCORE_KEY#'accuracy'\n",
    "answer_type_ext = tf_answer_type(score_key = score_key)\n",
    "\n",
    "ids_file_name = 'dataset_ids.test.pruned'  # None\n",
    "save_main_dir = f'{STATISTICS_PATH}.{ids_file_name}'\n",
    "stats_all = collect_stats_all(tf_answer_type(score_key = score_key), save_main_dir=save_main_dir)\n",
    "print(len(stats_all))\n",
    "plan_lengths = [1,10,19]\n",
    "\n",
    "save_dir = os.path.join(save_main_dir, 'tables', 'by_models')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# model_prompts_combos = [('small-models', SMALL_MODELS, PROMPT_TYPES), ('big-models', BIG_MODELS, ['few_shot_1', 'few_shot_5'])]\n",
    "model_prompts_combos = [('all-models', PROMPT_MODEL_NAMES, ['few_shot_1', 'few_shot_5'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T00:17:22.255992Z",
     "start_time": "2024-05-29T00:17:17.739717Z"
    }
   },
   "id": "8fb4feeb322b4ab0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def to_df(results_all, plan_lengths, answer_type, models=PROMPT_MODEL_NAMES,\n",
    "          prompt_types = PROMPT_TYPES,\n",
    "          domain = ALL_DOMAINS_KEY, subs = WITHOUT_RANDOM_SUB):\n",
    "    \n",
    "    index = []\n",
    "    data = []    \n",
    "    for plan_length in plan_lengths:\n",
    "        for ramifications in RAMIFICATION_TYPES:\n",
    "            index.append((plan_length, TO_PRETTY.get(ramifications, ramifications)))\n",
    "            data_columns = {}\n",
    "            for model_name in models:\n",
    "                for prompt_type in prompt_types:\n",
    "                    res_obj = filter_single_selector(results_all, plan_length, ALL_QUESTION_CATEGORIES_KEY, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "                    # print(res_obj)\n",
    "                    if res_obj:\n",
    "                        mean = res_obj['result']\n",
    "                        sem = None\n",
    "                        if res_obj['result_other']:\n",
    "                            sem = res_obj['result_other']['sem']\n",
    "                        not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                        final_res = (mean, sem, not_corrupted)\n",
    "                    else:\n",
    "                        final_res = (None, None, None)\n",
    "                    final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "                    final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "                    data_columns[(TO_PRETTY.get(model_name, model_name), TO_PRETTY.get(prompt_type, prompt_type))] = final_res\n",
    "            data.append(data_columns)\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def to_df_by_category(results_all, answer_type,  \n",
    "                      model_names = PROMPT_MODEL_NAMES,\n",
    "                      prompt_types= PROMPT_TYPES,\n",
    "                      ramifications = WITHOUT_RAMIFICATIONS,\n",
    "                      domain = ALL_DOMAINS_KEY, \n",
    "                      subs = WITHOUT_RANDOM_SUB,\n",
    "                      plan_length=19):\n",
    "\n",
    "    index = []\n",
    "    data = []    \n",
    "    for question_category in QUESTION_CATEGORIES:\n",
    "        index.append(question_category)\n",
    "        data_columns = {}\n",
    "        for model_name in model_names:\n",
    "            for prompt_type in prompt_types:\n",
    "                res_obj = filter_single_selector(results_all, plan_length, question_category, ramifications, model_name, prompt_type, domain, answer_type, subs)\n",
    "                if res_obj:\n",
    "                    mean = res_obj['result']\n",
    "                    sem = None\n",
    "                    if res_obj['result_other']:\n",
    "                        sem = res_obj['result_other']['sem']\n",
    "                    not_corrupted = res_obj['stats']['num_not_corrupted']\n",
    "                    final_res = (mean, sem, not_corrupted)\n",
    "                else:\n",
    "                    final_res = (None, None, None)\n",
    "                final_res = tuple([round(v*100, 2) if v else v for v in final_res ])\n",
    "                final_res = '${'+str(final_res[0])+'}_{'+str(final_res[1])+'}$'\n",
    "                data_columns[(TO_PRETTY.get(model_name,model_name), TO_PRETTY.get(prompt_type,prompt_type))] = final_res\n",
    "        data.append(data_columns)\n",
    "    return pd.DataFrame(data, index = index)\n",
    "\n",
    "def df_to_latex_table(df):\n",
    "        latex_table = df.to_latex(index=True, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)\n",
    "        return latex_table[latex_table.find('\\midrule'):].replace(\"bottomrule\", 'crap').replace(\"\\crap\", '').replace(\"\\end{tabular}\", '')\n",
    "\n",
    "def assemble_table(results_all, answer_type, domain, score_key=None):\n",
    "    latex_table_all = ''\n",
    "    with open('latex_table_template/top') as f:\n",
    "        latex_table_all += f.read() + '\\n'\n",
    "    latex_table_all += '\\n'.join([df_to_latex_table(to_df(results_all, answer_type, plan_length, domain)) for plan_length in PLAN_LENGTHS])\n",
    "    with open('latex_table_template/bottom') as f:\n",
    "        latex_table_all += f.read()\n",
    "    \n",
    "    caption = f'{answer_type}, {score_key} scores for {domain}'.replace('_', ' ')\n",
    "    latex_table_all = latex_table_all.replace('REPLACE_CAPTION_KEY', caption)\n",
    "    \n",
    "    return latex_table_all\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T00:17:22.885011Z",
     "start_time": "2024-05-29T00:17:22.867907Z"
    }
   },
   "id": "dd77fda858739d0e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 (G-2b, FS-1)      (G-2b, FS-5)      (G-7b, FS-1)  \\\n",
      "(1, W R)     ${46.25}_{1.22}$  ${36.78}_{1.34}$  ${51.55}_{1.22}$   \n",
      "(1, W/O R)   ${46.59}_{1.22}$  ${36.24}_{1.35}$   ${51.4}_{1.22}$   \n",
      "(10, W R)    ${44.76}_{1.21}$  ${34.72}_{1.32}$  ${51.03}_{1.21}$   \n",
      "(10, W/O R)  ${43.46}_{1.21}$  ${33.31}_{1.32}$  ${50.44}_{1.22}$   \n",
      "(19, W R)    ${44.97}_{1.23}$  ${29.97}_{1.36}$  ${49.12}_{1.23}$   \n",
      "(19, W/O R)  ${44.66}_{1.23}$  ${29.79}_{1.37}$  ${48.74}_{1.24}$   \n",
      "\n",
      "                 (G-7b, FS-5)      (L-7b, FS-1)      (L-7b, FS-5)  \\\n",
      "(1, W R)      ${54.31}_{1.4}$  ${47.73}_{1.23}$  ${53.47}_{1.75}$   \n",
      "(1, W/O R)    ${52.83}_{1.4}$  ${48.45}_{1.22}$  ${52.72}_{1.76}$   \n",
      "(10, W R)    ${59.68}_{1.38}$   ${48.7}_{1.23}$  ${55.38}_{1.96}$   \n",
      "(10, W/O R)  ${57.94}_{1.38}$  ${46.97}_{1.21}$  ${52.53}_{1.99}$   \n",
      "(19, W R)    ${56.26}_{1.48}$  ${47.03}_{1.26}$   ${52.8}_{2.58}$   \n",
      "(19, W/O R)   ${56.2}_{1.48}$   ${48.2}_{1.23}$  ${51.21}_{2.59}$   \n",
      "\n",
      "                (L-13b, FS-1)     (L-13b, FS-5)    (Gemini, FS-1)  \\\n",
      "(1, W R)     ${51.08}_{1.22}$  ${55.32}_{1.75}$  ${67.32}_{1.15}$   \n",
      "(1, W/O R)   ${50.59}_{1.22}$  ${56.31}_{1.74}$  ${67.08}_{1.15}$   \n",
      "(10, W R)    ${48.78}_{1.22}$  ${53.04}_{1.97}$  ${62.43}_{1.18}$   \n",
      "(10, W/O R)  ${50.26}_{1.21}$  ${50.79}_{1.99}$  ${63.14}_{1.17}$   \n",
      "(19, W R)    ${50.06}_{1.24}$  ${57.87}_{2.55}$   ${62.21}_{1.2}$   \n",
      "(19, W/O R)  ${50.88}_{1.23}$  ${56.57}_{2.57}$   ${60.99}_{1.2}$   \n",
      "\n",
      "               (Gemini, FS-5)    (gpt-4o, FS-1)   (gpt-4o, FS-5)  \n",
      "(1, W R)       ${69.4}_{1.2}$  ${77.55}_{1.02}$  ${None}_{None}$  \n",
      "(1, W/O R)   ${68.87}_{1.22}$  ${76.31}_{1.04}$  ${None}_{None}$  \n",
      "(10, W R)    ${64.92}_{1.24}$  ${72.66}_{1.08}$  ${None}_{None}$  \n",
      "(10, W/O R)  ${64.95}_{1.25}$  ${72.61}_{1.09}$  ${None}_{None}$  \n",
      "(19, W R)    ${63.11}_{1.27}$  ${69.45}_{1.14}$  ${None}_{None}$  \n",
      "(19, W/O R)   ${64.3}_{1.27}$  ${68.42}_{1.15}$  ${None}_{None}$  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paveldolin/dev/research/current/reasoning_about_actions/pipeline/src/analysis/tables/helpers.py:44: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=True, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 (G-2b, FS-1)      (G-2b, FS-5)      (G-7b, FS-1)  \\\n",
      "(1, W R)      ${46.09}_{1.3}$  ${44.32}_{2.58}$  ${49.28}_{1.22}$   \n",
      "(1, W/O R)   ${46.03}_{1.29}$  ${40.69}_{2.53}$  ${48.63}_{1.22}$   \n",
      "(10, W R)    ${45.52}_{1.36}$  ${50.0}_{35.36}$  ${50.38}_{1.21}$   \n",
      "(10, W/O R)  ${44.22}_{1.34}$   ${100.0}_{0.0}$   ${49.7}_{1.22}$   \n",
      "(19, W R)    ${46.22}_{1.49}$   ${None}_{None}$  ${48.38}_{1.24}$   \n",
      "(19, W/O R)  ${43.94}_{1.47}$   ${None}_{None}$  ${49.26}_{1.24}$   \n",
      "\n",
      "                 (G-7b, FS-5)      (L-7b, FS-1)     (L-7b, FS-5)  \\\n",
      "(1, W R)     ${56.86}_{1.53}$  ${47.18}_{1.36}$  ${55.25}_{3.1}$   \n",
      "(1, W/O R)   ${55.22}_{1.57}$  ${47.63}_{1.35}$   ${53.5}_{3.2}$   \n",
      "(10, W R)    ${57.31}_{1.63}$  ${45.42}_{1.42}$  ${None}_{None}$   \n",
      "(10, W/O R)  ${56.73}_{1.66}$  ${45.54}_{1.41}$  ${None}_{None}$   \n",
      "(19, W R)     ${53.9}_{2.05}$   ${43.8}_{1.62}$  ${None}_{None}$   \n",
      "(19, W/O R)    ${53.9}_{2.1}$  ${43.69}_{1.64}$  ${None}_{None}$   \n",
      "\n",
      "                (L-13b, FS-1)     (L-13b, FS-5)    (Gemini, FS-1)  \\\n",
      "(1, W R)     ${52.67}_{1.36}$  ${59.92}_{3.06}$  ${62.41}_{1.18}$   \n",
      "(1, W/O R)   ${53.68}_{1.35}$  ${59.26}_{3.15}$  ${61.88}_{1.18}$   \n",
      "(10, W R)    ${50.77}_{1.42}$   ${None}_{None}$  ${59.67}_{1.19}$   \n",
      "(10, W/O R)  ${50.92}_{1.42}$   ${None}_{None}$  ${59.55}_{1.19}$   \n",
      "(19, W R)    ${51.82}_{1.63}$   ${None}_{None}$  ${58.92}_{1.21}$   \n",
      "(19, W/O R)  ${53.46}_{1.65}$   ${None}_{None}$  ${57.27}_{1.22}$   \n",
      "\n",
      "               (Gemini, FS-5)    (gpt-4o, FS-1)   (gpt-4o, FS-5)  \n",
      "(1, W R)     ${63.23}_{1.26}$  ${72.53}_{1.09}$  ${None}_{None}$  \n",
      "(1, W/O R)   ${63.23}_{1.26}$   ${71.38}_{1.1}$  ${None}_{None}$  \n",
      "(10, W R)    ${60.44}_{1.27}$  ${67.78}_{1.14}$  ${None}_{None}$  \n",
      "(10, W/O R)  ${60.44}_{1.27}$  ${66.61}_{1.14}$  ${None}_{None}$  \n",
      "(19, W R)     ${58.37}_{1.3}$   ${62.63}_{1.2}$  ${None}_{None}$  \n",
      "(19, W/O R)   ${58.37}_{1.3}$   ${61.72}_{1.2}$  ${None}_{None}$  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paveldolin/dev/research/current/reasoning_about_actions/pipeline/src/analysis/tables/helpers.py:44: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=True, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)\n"
     ]
    }
   ],
   "source": [
    "for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "    for model_save_name, model_names, prompt_types in model_prompts_combos:\n",
    "        df = to_df(stats_all, plan_lengths, answer_type, prompt_types=prompt_types, models=model_names, subs=subs)\n",
    "        print(df)\n",
    "        \n",
    "        caption_nl = f'performance of {model_save_name} on the test set, {subs}'.replace('_', ' ')\n",
    "        latex_table = latex_table_mods(to_latex_table(df, caption_nl, label=model_save_name))\n",
    "        save_key = f'all.{model_save_name}.{subs}'\n",
    "        with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "            f.write(latex_table)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T00:17:25.696255Z",
     "start_time": "2024-05-29T00:17:23.702589Z"
    }
   },
   "id": "5b5a15905194ac6a",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot By Category"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aad3ef5e3825084"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          (G-2b, FS-1)      (G-2b, FS-5)      (G-7b, FS-1)  \\\n",
      "object_tracking       ${40.57}_{2.14}$  ${28.61}_{2.32}$  ${47.16}_{2.17}$   \n",
      "fluent_tracking        ${43.11}_{2.2}$   ${20.99}_{2.2}$  ${50.88}_{2.21}$   \n",
      "state_tracking        ${47.73}_{7.53}$     ${0.0}_{0.0}$  ${59.09}_{7.41}$   \n",
      "action_executability  ${53.75}_{5.57}$   ${36.0}_{6.79}$  ${51.28}_{5.66}$   \n",
      "effects               ${49.36}_{2.82}$  ${37.44}_{3.27}$   ${46.3}_{2.83}$   \n",
      "numerical_reasoning   ${46.25}_{5.57}$   ${40.0}_{6.32}$  ${38.75}_{5.45}$   \n",
      "hallucination         ${50.63}_{5.62}$  ${59.18}_{7.02}$  ${56.96}_{5.57}$   \n",
      "\n",
      "                           (G-7b, FS-5)      (L-7b, FS-1)       (L-7b, FS-5)  \\\n",
      "object_tracking        ${52.23}_{2.56}$  ${48.48}_{2.17}$    ${50.0}_{4.26}$   \n",
      "fluent_tracking        ${53.64}_{2.69}$  ${42.02}_{2.18}$   ${45.65}_{5.19}$   \n",
      "state_tracking        ${57.89}_{11.33}$  ${54.55}_{7.51}$    ${None}_{None}$   \n",
      "action_executability    ${54.0}_{7.05}$  ${46.25}_{5.57}$  ${61.54}_{13.49}$   \n",
      "effects                ${63.93}_{3.24}$   ${53.31}_{2.8}$    ${57.47}_{5.3}$   \n",
      "numerical_reasoning    ${48.33}_{6.45}$  ${51.25}_{5.59}$   ${42.31}_{9.69}$   \n",
      "hallucination          ${81.63}_{5.53}$  ${61.25}_{5.45}$  ${64.71}_{11.59}$   \n",
      "\n",
      "                         (L-13b, FS-1)      (L-13b, FS-5)    (Gemini, FS-1)  \\\n",
      "object_tracking       ${55.49}_{2.16}$   ${60.14}_{4.17}$  ${67.42}_{2.04}$   \n",
      "fluent_tracking        ${45.33}_{2.2}$   ${55.43}_{5.18}$  ${58.75}_{2.17}$   \n",
      "state_tracking        ${47.73}_{7.53}$    ${None}_{None}$  ${59.09}_{7.41}$   \n",
      "action_executability   ${50.0}_{5.59}$  ${61.54}_{13.49}$   ${52.5}_{5.58}$   \n",
      "effects                ${51.1}_{2.81}$   ${51.72}_{5.36}$  ${54.89}_{2.79}$   \n",
      "numerical_reasoning    ${50.0}_{5.59}$   ${46.15}_{9.78}$  ${48.75}_{5.59}$   \n",
      "hallucination          ${58.75}_{5.5}$  ${70.59}_{11.05}$  ${78.75}_{4.57}$   \n",
      "\n",
      "                        (Gemini, FS-5)    (gpt-4o, FS-1)   (gpt-4o, FS-5)  \n",
      "object_tracking        ${67.47}_{2.2}$  ${74.29}_{1.91}$  ${None}_{None}$  \n",
      "fluent_tracking       ${61.04}_{2.31}$  ${73.63}_{1.95}$  ${None}_{None}$  \n",
      "state_tracking         ${56.1}_{7.75}$  ${59.09}_{7.41}$  ${None}_{None}$  \n",
      "action_executability  ${51.52}_{6.15}$  ${55.13}_{5.63}$  ${None}_{None}$  \n",
      "effects               ${64.87}_{2.86}$  ${53.97}_{2.81}$  ${None}_{None}$  \n",
      "numerical_reasoning    ${50.0}_{5.98}$  ${51.28}_{5.66}$  ${None}_{None}$  \n",
      "hallucination         ${94.12}_{2.85}$  ${88.61}_{3.57}$  ${None}_{None}$  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paveldolin/dev/research/current/reasoning_about_actions/pipeline/src/analysis/tables/helpers.py:44: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=True, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          (G-2b, FS-1)     (G-2b, FS-5)      (G-7b, FS-1)  \\\n",
      "object_tracking       ${42.82}_{2.46}$  ${None}_{None}$  ${45.63}_{2.17}$   \n",
      "fluent_tracking        ${41.29}_{2.8}$  ${None}_{None}$  ${50.69}_{2.22}$   \n",
      "state_tracking         ${None}_{None}$  ${None}_{None}$  ${52.27}_{7.53}$   \n",
      "action_executability  ${38.71}_{6.19}$  ${None}_{None}$   ${50.0}_{5.66}$   \n",
      "effects               ${47.21}_{3.27}$  ${None}_{None}$  ${50.79}_{2.82}$   \n",
      "numerical_reasoning   ${47.83}_{6.01}$  ${None}_{None}$  ${46.25}_{5.57}$   \n",
      "hallucination         ${53.33}_{6.44}$  ${None}_{None}$   ${58.75}_{5.5}$   \n",
      "\n",
      "                          (G-7b, FS-5)      (L-7b, FS-1)     (L-7b, FS-5)  \\\n",
      "object_tracking        ${50.87}_{3.3}$  ${40.47}_{2.66}$  ${None}_{None}$   \n",
      "fluent_tracking       ${49.62}_{4.34}$    ${36.0}_{3.2}$  ${None}_{None}$   \n",
      "state_tracking         ${None}_{None}$   ${None}_{None}$  ${None}_{None}$   \n",
      "action_executability   ${61.9}_{10.6}$  ${43.75}_{7.16}$  ${None}_{None}$   \n",
      "effects               ${64.17}_{4.38}$   ${53.65}_{3.6}$  ${None}_{None}$   \n",
      "numerical_reasoning   ${41.67}_{8.22}$  ${54.24}_{6.49}$  ${None}_{None}$   \n",
      "hallucination         ${66.67}_{9.62}$   ${50.0}_{7.37}$  ${None}_{None}$   \n",
      "\n",
      "                         (L-13b, FS-1)    (L-13b, FS-5)    (Gemini, FS-1)  \\\n",
      "object_tracking        ${56.6}_{2.68}$  ${None}_{None}$  ${65.91}_{2.06}$   \n",
      "fluent_tracking       ${47.56}_{3.33}$  ${None}_{None}$   ${53.11}_{2.2}$   \n",
      "state_tracking         ${None}_{None}$  ${None}_{None}$  ${47.73}_{7.53}$   \n",
      "action_executability   ${62.5}_{6.99}$  ${None}_{None}$   ${52.5}_{5.58}$   \n",
      "effects               ${55.21}_{3.59}$  ${None}_{None}$  ${50.16}_{2.81}$   \n",
      "numerical_reasoning   ${45.76}_{6.49}$  ${None}_{None}$  ${51.25}_{5.59}$   \n",
      "hallucination         ${52.17}_{7.37}$  ${None}_{None}$  ${71.25}_{5.06}$   \n",
      "\n",
      "                        (Gemini, FS-5)    (gpt-4o, FS-1)   (gpt-4o, FS-5)  \n",
      "object_tracking       ${66.81}_{2.18}$   ${66.1}_{2.06}$  ${None}_{None}$  \n",
      "fluent_tracking       ${54.16}_{2.36}$  ${63.23}_{2.13}$  ${None}_{None}$  \n",
      "state_tracking        ${55.81}_{7.57}$  ${56.82}_{7.47}$  ${None}_{None}$  \n",
      "action_executability  ${52.94}_{6.05}$  ${56.25}_{5.55}$  ${None}_{None}$  \n",
      "effects               ${52.84}_{2.97}$   ${52.68}_{2.8}$  ${None}_{None}$  \n",
      "numerical_reasoning   ${51.39}_{5.89}$   ${47.5}_{5.58}$  ${None}_{None}$  \n",
      "hallucination         ${65.22}_{5.73}$  ${81.25}_{4.36}$  ${None}_{None}$  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paveldolin/dev/research/current/reasoning_about_actions/pipeline/src/analysis/tables/helpers.py:44: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = df.to_latex(index=True, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)\n"
     ]
    }
   ],
   "source": [
    "plan_length = 19\n",
    "for subs in [WITHOUT_RANDOM_SUB, WITH_RANDOM_SUB]:\n",
    "    for model_save_name, model_names, prompt_types in model_prompts_combos:\n",
    "        df2 = to_df_by_category(stats_all, answer_type, model_names=model_names, prompt_types=prompt_types, subs=subs)\n",
    "        print(df2)\n",
    "        \n",
    "        caption_nl = f'performance of {model_save_name} on the test set by categories, {subs}, pl-{plan_length}'\n",
    "        save_key = f'by_categories.{model_save_name}.{subs}'\n",
    "        \n",
    "        latex_table_all = latex_table_mods(to_latex_table(df2, caption_nl, label=save_key))\n",
    "        with open(os.path.join(save_dir, f'{save_key}.tex'), 'w') as f:\n",
    "            f.write(latex_table_all)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-29T00:17:33.465195Z",
     "start_time": "2024-05-29T00:17:31.067351Z"
    }
   },
   "id": "da82c99c16ce0495",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1378f27bd37e213"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
